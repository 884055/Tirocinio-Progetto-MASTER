{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASTER - Notebook 1\n",
    "### Matteo Grazioso 884055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disply all columns and all rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fileS contain the data of the validation of tickets in the city of public transport of Venice.\n",
    "\n",
    "# Import the data into a dataframe of a txt file \n",
    "path = 'data/raw/validazioni.txt'                     # Period: 2022-05-13 to 2022-07-15\n",
    "# path = 'data/raw/esportazioneCompleta.txt'            # Period: 2023-01-23 to 2023-03-14\n",
    "\n",
    "df = pd.read_csv(path, header=0, sep='\\t')\n",
    "# Save the name of the file in a variable for future use extracting the name of the file from the path\n",
    "file_name = path.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the last 5 rows of the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the data with the first 10% of the rows\n",
    "# df = df.iloc[:int(len(df)*0.1), :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates and hour of the validation of the ticket are in the same column 'DATA_VALIDAZIONE'\n",
    "# Split the column 'DATA_VALIDAZIONE' into two columns 'DATA' and 'ORA' and convert them to datetime format\n",
    "df.insert(0, 'DATA', pd.to_datetime(df['DATA_VALIDAZIONE'].str.split(' ').str[0], format='%d/%m/%Y'))\n",
    "df.insert(1, 'ORA', pd.to_datetime(df['DATA_VALIDAZIONE'].str.split(' ').str[1], format='%H:%M').dt.time)\n",
    "\n",
    "# Drop the column 'DATA_VALIDAZIONE'\n",
    "# df.drop('DATA_VALIDAZIONE', axis=1, inplace=True)\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the format of the timestamp\n",
    "df['DATA_VALIDAZIONE'] = pd.to_datetime(df['DATA_VALIDAZIONE'], format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the date of the first and last validation using both data and hour\n",
    "print('First validation: ', df['DATA'].min(), df['ORA'].min())\n",
    "print('Last validation: ', df['DATA'].max(), df['ORA'].max())\n",
    "\n",
    "# Print the number of Serial numbers\n",
    "print('Number of Serial numbers: ', df['SERIALE'].nunique())\n",
    "\n",
    "# Print the number of validation (rows)\n",
    "print('Number of validation: ', df.shape[0])\n",
    "\n",
    "# Print the number of tickets\n",
    "print('Number of tickets: ', df['DESCRIZIONE_TITOLO'].nunique())\n",
    "# Print the number of titolo\n",
    "print('Number of titolo: ', df['TITOLO'].nunique())\n",
    "# TODO: why the number of unique TITOLO is different from the number of DESCRIZIONE_TITOLO?\n",
    "\n",
    "# Print the number of FERMATA\n",
    "print('Number of FERMATA: ', df['FERMATA'].nunique())\n",
    "# Print the number of DESCRIZIONE\n",
    "print('Number of DESCRIZIONE: ', df['DESCRIZIONE'].nunique())\n",
    "# TODO: why the number of unique DESCRIZIONE is different from the number of FERMATA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is the most used ticket?\n",
    "df['DESCRIZIONE_TITOLO'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is the most frequent validation in date and hour?\n",
    "# Date and hour are in two different columns; DATA_VALIDAZIONE does not exist anymore\n",
    "df.groupby(['DATA', 'ORA'])['SERIALE'].count().sort_values(ascending=False).head(10)\n",
    "# TODO: #4 Re-aswer the question of the most frequent validation after cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is the most frequent FERMATA?\n",
    "df['DESCRIZIONE'].value_counts().head(10)\n",
    "# TODO: #4 Re-aswer the question of the most frequent FERMATA after cleaning operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with the code profile of the ticket\n",
    "df.insert(7, \"TICKET_CODE\", 'TBD')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column will be filled with the code of the ticket profile according to the ticket type and the ticket validity as follows:\n",
    "\n",
    "**1.** One-day ticket\n",
    "\n",
    "**2.** Two-day ticket\n",
    "\n",
    "**3.** Three-day ticket\n",
    "\n",
    "**4.** Weekly ticket (Seven-day ticket)\n",
    "\n",
    "**5.** Monthly ticket\n",
    "\n",
    "**5-STUD.** Monthly ticket for students\n",
    "\n",
    "**5-RET.** Monthly ticket for retirees\n",
    "\n",
    "**5-WKRS.** Monthly ticket for workers\n",
    "\n",
    "**6.** Annual ticket\n",
    "\n",
    "**6-STUD.** Annual ticket for students\n",
    "\n",
    "**6-RET.** Annual ticket for retirees\n",
    "\n",
    "**6-WKRS.** Annual ticket for workers\n",
    "\n",
    "**7.** 75 minutes ticket\n",
    "\n",
    "**8.** Other ticket (if it is necessary to add other types of tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the ticket code and the ticket profile\n",
    "dict_tickets = {'1': 'One-day ticket', '2': 'Two-day ticket', '3': 'Three-day ticket', \n",
    "                '4': 'Seven-day ticket', \n",
    "                '5': 'Monthly ticket', '5-STUD': 'Monthly ticket for students',\n",
    "                '5-RET': 'Monthly ticket for retired', '5-WKRS': 'Monthly ticket for workers',\n",
    "                '6': 'Annual ticket', '6-STUD': 'Annual ticket for students', '6-RET': 'Annual ticket for retired',\n",
    "                '6-WKRS': 'Annual ticket for workers',\n",
    "                '7': '75 minutes ticket', '8': 'Other ticket'}\n",
    "\n",
    "# Export the dictionary to a json file\n",
    "with open('data/dictionaries/dict_ticket_codes.json', 'w') as fp:\n",
    "    json.dump(dict_tickets, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique values are there in the column 'DESCRIZIONE_TITOLO'?\n",
    "df['DESCRIZIONE_TITOLO'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are the unique values of the column 'DESCRIZIONE_TITOLO'?\n",
    "df['DESCRIZIONE_TITOLO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of unique values of the column 'DESCRIZIONE_TITOLO'\n",
    "num_unique_DESCRIZIONE_TITOLO = len(df['DESCRIZIONE_TITOLO'].unique())\n",
    "print('The number of unique values of the column DESCRIZIONE_TITOLO is: ', num_unique_DESCRIZIONE_TITOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the column 'DESCRIZIONE_TITOLO' into upper case \n",
    "df['DESCRIZIONE_TITOLO'] = df['DESCRIZIONE_TITOLO'].str.upper()\n",
    "# Count the number of unique values of the column 'DESCRIZIONE_TITOLO'\n",
    "df['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-day tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which type of ticket are one-day tickets and how many are there?\n",
    "df[df['DESCRIZIONE_TITOLO'].str.contains('GIORNALIERO|24H|24ORE|24 ORE|DAILY')]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity \n",
    "df.loc[df['DESCRIZIONE_TITOLO'].str.contains('GIORNALIERO|24H|24ORE|24 ORE|DAILY'), 'TICKET_CODE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TICKET_CODE = 1: Information about one-day tickets\n",
    "print(\"The number of one-day tickets is: \", df[df['TICKET_CODE'] == '1'].shape[0])\n",
    "print(\"The number of tickets for each type of one-day ticket is: \")\n",
    "df[df['TICKET_CODE'] == '1']['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information about the tickets with code 1 related to the serial number: \")\n",
    "df[df['TICKET_CODE'] == '1'].groupby('DESCRIZIONE_TITOLO')['SERIALE'].value_counts().groupby('DESCRIZIONE_TITOLO').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two days tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which type of ticket are two-day tickets and how many are there?\n",
    "df[df['DESCRIZIONE_TITOLO'].str.contains('48H|48ORE|48 ORE')]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[df['DESCRIZIONE_TITOLO'].str.contains('48H|48ORE|48 ORE'), 'TICKET_CODE'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICKET_CODE = 2: Information about two-day tickets\n",
    "print(\"The number of two-day tickets is: \", df[df['TICKET_CODE'] == '2'].shape[0])\n",
    "print(\"The number of tickets for each type of two-day ticket is: \")\n",
    "df[df['TICKET_CODE'] == '2']['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information about the tickets with code 2 related to the serial number: \")\n",
    "df[df['TICKET_CODE'] == '2'].groupby('DESCRIZIONE_TITOLO')['SERIALE'].value_counts().groupby('DESCRIZIONE_TITOLO').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three days tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which type of ticket are three-day tickets and how many are there?\n",
    "# Do not consider the ticket that contains also 75\n",
    "df[df['DESCRIZIONE_TITOLO'].str.contains('72H|72ORE|72 ORE')]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[df['DESCRIZIONE_TITOLO'].str.contains('72H|72ORE|72 ORE'), 'TICKET_CODE'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICKET_CODE = 3: Information about three-day tickets\n",
    "print(\"The number of three-day tickets is: \", df[df['TICKET_CODE'] == '3'].shape[0])\n",
    "print(\"The number of tickets for each type of three-day ticket is: \")\n",
    "df[df['TICKET_CODE'] == '3']['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information about the tickets with code 3 related to the serial number: \")\n",
    "df[df['TICKET_CODE'] == '3'].groupby('DESCRIZIONE_TITOLO')['SERIALE'].value_counts().groupby('DESCRIZIONE_TITOLO').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seven days tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which type of ticket are weekly tickets and how many are there?\n",
    "# Exclude the tickets that contains also 72, 75 that are three-day tickets, 17, 48h, 57 that are other types of tickets and\n",
    "# 'tratt*' and 'tr' that are reserved to specific routes\n",
    "df[df['DESCRIZIONE_TITOLO'].str.contains('7GG|7DAYS|7 DAYS')]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[df['DESCRIZIONE_TITOLO'].str.contains('7GG|7DAYS|7 DAYS'), 'TICKET_CODE'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICKET_CODE = 4: Information about weekly tickets\n",
    "print(\"The number of weekly tickets is: \", df[df['TICKET_CODE'] == '4'].shape[0])\n",
    "print(\"The number of tickets for each type of weekly ticket is: \")\n",
    "df[df['TICKET_CODE'] == '4']['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information about the tickets with code 4 related to the serial number: \")\n",
    "df[df['TICKET_CODE'] == '4'].groupby('DESCRIZIONE_TITOLO')['SERIALE'].value_counts().groupby('DESCRIZIONE_TITOLO').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whick type of ticket are monthly tickets and how many are there?\n",
    "df[df['DESCRIZIONE_TITOLO'].str.contains('MENSILE|30GG|30 GG|MENS')]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[df['DESCRIZIONE_TITOLO'].str.contains('MENSILE|30GG|30 GG|MENS'), 'TICKET_CODE'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If DESCRIZIONE_TITOLO contains 'STUDENTE' or 'STUD' update the column 'TICKET_CODE' with '5-STUD' only for the tickets with code 5\n",
    "df.loc[(df['TICKET_CODE'] == '5') & (df['DESCRIZIONE_TITOLO'].str.contains('STUDENTE|STUD|STUD')), 'TICKET_CODE'] = '5-STUD'\n",
    "# If DESCRIZIONE_TITOLO contains 'LAVORATORE' or 'LAV' update the column 'TICKET_CODE' with '5-WKRS' only for the tickets with code 5\n",
    "df.loc[(df['TICKET_CODE'] == '5') & (df['DESCRIZIONE_TITOLO'].str.contains('LAVORATORE|LAV|LAV')), 'TICKET_CODE'] = '5-WKRS'\n",
    "# If DESCRIZIONE_TITOLO contains 'OVER 65' or '65+' or 'PENSIONATI' update the column 'TICKET_CODE' with '5-RET' only for the tickets with code 5\n",
    "df.loc[(df['TICKET_CODE'] == '5') & (df['DESCRIZIONE_TITOLO'].str.contains('OVER 65|65+|PENSIONATI')), 'TICKET_CODE'] = '5-RET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the page of agevolation of specific categories of people available at the site web of ACTV \n",
    "# (https://actv.avmspa.it/it/content/categorie-agevolate-0), the DDRG 1201-1297/2022 tickets are monthly tickets for blind people\n",
    "\n",
    "# Which type of ticket are yearly tickets for blind people and how many are there?\n",
    "df[df['DESCRIZIONE_TITOLO'].str.contains('DDGR1201-1297/2022')]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[df['DESCRIZIONE_TITOLO'].str.contains('DDGR1201-1297/2022'), 'TICKET_CODE'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICKET_CODE = 5: Information about monthly tickets\n",
    "print(\"The number of monthly tickets is: \", df[df['TICKET_CODE'] == '5'].shape[0])\n",
    "print(\"The number of monthly tickets for students is: \", df[df['TICKET_CODE'] == '5-STUD'].shape[0])\n",
    "print(\"The number of monthly tickets for workers is: \", df[df['TICKET_CODE'] == '5-WKRS'].shape[0])\n",
    "print(\"The number of monthly tickets for retired people is: \", df[df['TICKET_CODE'] == '5-RET'].shape[0])\n",
    "\n",
    "print(\"The number of tickets for each type of monthly ticket (including the subtypes) is: \")\n",
    "df[df['TICKET_CODE'].isin(['5', '5-STUD', '5-WKRS', '5-RET'])].groupby('TICKET_CODE')['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information about the tickets with code 5 (including the subtypes) related to the serial number: \")\n",
    "df[df['TICKET_CODE'].isin(['5', '5-STUD', '5-WKRS', '5-RET'])].groupby(['TICKET_CODE', 'DESCRIZIONE_TITOLO'])['SERIALE'].value_counts().groupby(['TICKET_CODE', 'DESCRIZIONE_TITOLO']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which type of ticket are yearly tickets and how many are there?\n",
    "df[df['DESCRIZIONE_TITOLO'].str.contains('ANNUALE|ANN|12MESI|12 MESI')]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[df['DESCRIZIONE_TITOLO'].str.contains('ANNUALE|ANN|12MESI|12 MESI'), 'TICKET_CODE'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If DESCRIZIONE_TITOLO contains 'STUDENTE' or 'STUD' update the column 'TICKET_CODE' with '6-STUD' only for the tickets with code 6\n",
    "df.loc[(df['TICKET_CODE'] == '6') & (df['DESCRIZIONE_TITOLO'].str.contains('STUDENTE|STUD|STUD')), 'TICKET_CODE'] = '6-STUD'\n",
    "# If DESCRIZIONE_TITOLO contains 'LAVORATORE' or 'LAV' update the column 'TICKET_CODE' with '6-WKRS' only for the tickets with code 6\n",
    "df.loc[(df['TICKET_CODE'] == '6') & (df['DESCRIZIONE_TITOLO'].str.contains('LAVORATORE|LAV|LAV')), 'TICKET_CODE'] = '6-WKRS'\n",
    "# If DESCRIZIONE_TITOLO contains 'OVER 65' or '65+' or 'PENSIONATI' update the column 'TICKET_CODE' with '6-RET' only for the tickets with code 6\n",
    "df.loc[(df['TICKET_CODE'] == '6') & (df['DESCRIZIONE_TITOLO'].str.contains('OVER 65|65+|PENSIONATI')), 'TICKET_CODE'] = '6-RET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the page of agevolation of specific categories of people available at the site web of ACTV \n",
    "# (https://actv.avmspa.it/it/content/categorie-agevolate-0), the for OVER 75 are yearly tickets for free\n",
    "\n",
    "# Which type of ticket are yearly tickets for OVER 75 and how many are there?\n",
    "df[df['DESCRIZIONE_TITOLO'].str.contains('OVER 75|OVER75|PENSIONATI')]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[df['DESCRIZIONE_TITOLO'].str.contains('OVER 75|OVER75|PENSIONATI'), 'TICKET_CODE'] = '6-RET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the page of yearly tickets available at the site web of ACTV \n",
    "# (https://actv.avmspa.it/it/content/abbonamento-annuale-0), the bus pass for students has a validity of 12 months \n",
    "\n",
    "# Which type of ticket are yearly tickets for students and how many are there?\n",
    "# Exclude the tickets that have already the field TICKET_CODE populated with 5-STUD or 6-STUD\n",
    "df[(df['DESCRIZIONE_TITOLO'].str.contains('STUDENTE|STUD|STUD')) & ~ (df['TICKET_CODE'].isin(['5-STUD', '6-STUD']))]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[(df['DESCRIZIONE_TITOLO'].str.contains('STUDENTE|STUD|STUD')) & ~ (df['TICKET_CODE'].isin(['5-STUD', '6-STUD'])), 'TICKET_CODE'] = '6-STUD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICKET_CODE = 6: Information about annual tickets\n",
    "print(\"The number of annual tickets is: \", df[df['TICKET_CODE'] == '6'].shape[0])\n",
    "print(\"The number of annual tickets for students is: \", df[df['TICKET_CODE'] == '6-STUD'].shape[0])\n",
    "print(\"The number of annual tickets for workers is: \", df[df['TICKET_CODE'] == '6-WKRS'].shape[0])\n",
    "print(\"The number of annual tickets for retired people is: \", df[df['TICKET_CODE'] == '6-RET'].shape[0])\n",
    "\n",
    "print(\"The number of tickets for each type of annual ticket (including the subtypes) is: \")\n",
    "df[df['TICKET_CODE'].isin(['6', '6-STUD', '6-WKRS', '6-RET'])].groupby('TICKET_CODE')['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information about the tickets with code 6 (including the subtypes) related to the serial number: \")\n",
    "df[df['TICKET_CODE'].isin(['6', '6-STUD', '6-WKRS', '6-RET'])].groupby(['TICKET_CODE', 'DESCRIZIONE_TITOLO'])['SERIALE'].value_counts().groupby(['TICKET_CODE', 'DESCRIZIONE_TITOLO']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75 minutes tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which type of ticket are 75' (75 minutes) tickets and how many are there?\n",
    "df[df['DESCRIZIONE_TITOLO'].str.contains('75\\'|75MIN|75 MIN')]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[df['DESCRIZIONE_TITOLO'].str.contains('75\\'|75MIN|75 MIN'), 'TICKET_CODE'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICKET_CODE = 7: Information about 75' (75 minutes) tickets\n",
    "print(\"The number of 75' (75 minutes) tickets is: \", df[df['TICKET_CODE'] == '7'].shape[0])\n",
    "print(\"The number of tickets for each type of 75' (75 minutes) ticket is: \")\n",
    "df[df['TICKET_CODE'] == '7'].groupby('TICKET_CODE')['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information about the tickets with code 7 related to the serial number: \")\n",
    "df[df['TICKET_CODE'] == '7'].groupby('DESCRIZIONE_TITOLO')['SERIALE'].value_counts().groupby('DESCRIZIONE_TITOLO').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other types of tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which type of ticket are other tickets and how many are there?\n",
    "# The other tickets are the tickets that are not already classified in the previous categories\n",
    "df[~df['TICKET_CODE'].isin(['1', '2', '3', '4', '5', '5-STUD', '5-WKRS', '5-RET', '6', '6-STUD', '6-WKRS', '6-RET', '7'])]['DESCRIZIONE_TITOLO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the column 'TICKET_CODE' with the code of the ticket profile according to the ticket type and the ticket validity\n",
    "df.loc[~df['TICKET_CODE'].isin(['1','2','3','4','5','5-STUD','5-WKRS','5-RET','6','6-STUD','6-WKRS','6-RET','7']), 'TICKET_CODE'] = '8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICKET_CODE = 7b: Information about other tickets\n",
    "print(\"The number of other tickets is: \", df[df['TICKET_CODE'] == '8'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information about the tickets with code 8 related to the serial number: \")\n",
    "df[df['TICKET_CODE'] == '8'].groupby('DESCRIZIONE_TITOLO')['SERIALE'].value_counts().groupby('DESCRIZIONE_TITOLO').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the ticket profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of tickets for each ticket profile code ordered by the code of the ticket profile; print the name of the ticket profile using the dictionary 'dict_tickets'\n",
    "df['TICKET_CODE'].value_counts().sort_index().rename(dict_tickets).reindex(dict_tickets.values(), fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of tickets for each ticket profile code ordered by the code of the ticket profile, with a reference to the name of the serial number, is: \")\n",
    "df.groupby('TICKET_CODE')['SERIALE'].value_counts().groupby('TICKET_CODE').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of the column 'TICKET_CODE'\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "# Countplot of the column 'TICKET_CODE'\n",
    "sns.countplot(x='TICKET_CODE', data=df, order=df['TICKET_CODE'].value_counts().sort_index().index)\n",
    "plt.title('Countplot of the column TICKET_CODE', fontsize=20)\n",
    "plt.xlabel('Ticket code', fontsize=15)\n",
    "plt.ylabel('Count (in millions)', fontsize=15)\n",
    "\n",
    "# Change yticks to have a better visualization\n",
    "scale = np.arange(0, max(df['TICKET_CODE'].value_counts())+100000, 100000)\n",
    "plt.yticks(scale)\n",
    "\n",
    "# Add the percentage of each category on top of the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.3f}%'.format(100*p.get_height()/len(df)), (p.get_x()+0.3, p.get_height()+10000))\n",
    "\n",
    "# Add the count of each category on top of the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()+30000))\n",
    "\n",
    "# Add a padding on the top of the plot\n",
    "plt.subplots_adjust(top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a pie chart of the column 'TICKET_CODE'\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "df['TICKET_CODE'].value_counts().sort_index().plot.pie(startangle=90)\n",
    "\n",
    "# Add the name of the ticket profile on the pie chart\n",
    "plt.legend(labels=df['TICKET_CODE'].value_counts().sort_index().rename(dict_tickets).index, loc='center left', bbox_to_anchor=(1, 0, 0.5, 1), fontsize=15)\n",
    "\n",
    "plt.title('Pie chart of the column TICKET_CODE', fontsize=20)\n",
    "plt.ylabel('')\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the validation that are with TICKET_CODE = 8 (other tickets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_before = df.shape[0]\n",
    "\n",
    "# Delete 8 tickets because they are not useful for the analysis \n",
    "df = df[df['TICKET_CODE'] != '8']\n",
    "\n",
    "# Print the number of rows before and after the deletion of the 8 tickets and the difference\n",
    "print('The number of rows before the deletion of the 8 tickets is: {}'.format(shape_before))\n",
    "print('The number of rows after the deletion of the 8 tickets is: {}'.format(df.shape[0]))\n",
    "print('The difference is: {}'.format(shape_before - df.shape[0]))\n",
    "\n",
    "# TODO: to de-comment later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useless stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: #1 Remove useless rows that have a minimum temporal gap for the same serial and fermata\n",
    "# DE-COMMENT THE FOLLOWING LINES OF CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the serial with the hightest number of validations, and the same for each ticket profile, save the results in a dictionary\n",
    "dict_serial = {}\n",
    "for ticket in df['TICKET_CODE'].unique():\n",
    "    dict_serial[ticket] = df[df['TICKET_CODE'] == ticket]['SERIALE'].value_counts().index[0]\n",
    "\n",
    "# Print the serial with the hightest number of validations, and the same for each ticket profile\n",
    "for ticket in df['TICKET_CODE'].unique():\n",
    "  print('The serial with the hightest number of validations for the ticket profile {} is: {}'.format(ticket, dict_serial[ticket]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the serial and the fermata \n",
    "# df = df.groupby(['SERIALE', 'FERMATA']).apply(lambda x: x.sort_values(by='DATA_VALIDAZIONE', ascending=True))\n",
    "\n",
    "# Print the first 5 rows of the df\n",
    "# df.head()\n",
    "# DO NOT DE-COMMENT THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the df and drop the old index in order to have a new index starting from 0 to the number of rows\n",
    "# It is necessary to have a new index because the groupby function has created a multi-index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'MIN_TEMPORAL_GAP' that contains the minimum temporal gap between two validations for the same serial and fermata in minutes\n",
    "df = df.groupby(['SERIALE','DATA', 'FERMATA']).apply(lambda x: x.assign(MIN_TEMPORAL_GAP = x['DATA_VALIDAZIONE'].diff().dt.total_seconds()/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MIN_TEMPORAL_GAP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows have a minimum temporal gap equal to NaN?\n",
    "df[df['MIN_TEMPORAL_GAP'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning operation: remove the rows using the minimum temporal gap\n",
    "\n",
    "# Find a reasonable delta of MIN_TEMPORAL_GAP to remove the rows that have a minimum temporal gap for the same serial and fermata less than this delta\n",
    "# Print the minimum value of the column MIN_TEMPORAL_GAP\n",
    "print('The minimum value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].min()))\n",
    "\n",
    "# Print the maximum value of the column MIN_TEMPORAL_GAP\n",
    "print('The maximum value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].max()))\n",
    "\n",
    "# Print the mean value of the column MIN_TEMPORAL_GAP\n",
    "print('The mean value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].mean()))\n",
    "\n",
    "# Print the median value of the column MIN_TEMPORAL_GAP\n",
    "print('The median value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].median()))\n",
    "\n",
    "# Print the standard deviation of the column MIN_TEMPORAL_GAP\n",
    "print('The standard deviation of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].std()))\n",
    "\n",
    "# Print the 0.05th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 0.05th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.05)))\n",
    "\n",
    "# Print the 0.10th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 0.10th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.10)))\n",
    "\n",
    "# Print the 25th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 25th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.25)))\n",
    "\n",
    "# Print the 75th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 75th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.75)))\n",
    "\n",
    "# Print the 90th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 90th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.90)))\n",
    "\n",
    "# Print the 95th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 95th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.95)))\n",
    "\n",
    "# Print the 99th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 99th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.99)))\n",
    "\n",
    "# Print the 99.9th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 99.9th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.999)))\n",
    "\n",
    "# Decide the delta of MIN_TEMPORAL_GAP using the 25th percentile of the column MIN_TEMPORAL_G\n",
    "delta = df['MIN_TEMPORAL_GAP'].quantile(0.1)\n",
    "if delta == 0:\n",
    "    delta = df['MIN_TEMPORAL_GAP'].quantile(0.25)\n",
    "if delta == 0:\n",
    "    delta = df['MIN_TEMPORAL_GAP'].median()\n",
    "print('The delta of MIN_TEMPORAL_GAP is: {}'.format(delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning operation: remove the rows using the minimum temporal gap\n",
    "\n",
    "# Save the number of rows before the cleaning operation\n",
    "shape_before = df.shape[0]\n",
    "\n",
    "# Delete the rows that have a minimum temporal gap for the same serial and fermata more than the delta calculated before.\n",
    "# Do not remove the rows with NaN values because they are the first validations of the day of a specific serial and fermata usefull for the analysis\n",
    "df = df[(df['MIN_TEMPORAL_GAP'] > delta) | (df['MIN_TEMPORAL_GAP'].isna())]\n",
    "\n",
    "# Print the number of rows before and after the cleaning operation and the difference\n",
    "print('The number of rows before the cleaning operation is: {}'.format(shape_before))\n",
    "print('The number of rows after the cleaning operation is: {}'.format(df.shape[0]))\n",
    "print('The difference is: {}'.format(shape_before - df.shape[0]))\n",
    "# Calculate the percentage of rows that has just been deleted\n",
    "print('The percentage of rows that has just been deleted is: {}%'.format(round((shape_before - df.shape[0])/shape_before*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the column MIN_TEMPORAL_GAP because it is not useful anymore\n",
    "df.drop('MIN_TEMPORAL_GAP', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stops similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of unique values in the column 'DESCRIZIONE' that are the names of the stops\n",
    "print('The number of unique values in the column DESCRIZIONE is: {}'.format(df['DESCRIZIONE'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_prefix(string_list):\n",
    "    \"\"\"\n",
    "        This function returns the common prefix of a list of strings.\n",
    "        If there is no common prefix, it returns an empty string.\n",
    "        :param string_list: list of strings\n",
    "        :return: string that is the common prefix of the list of strings\n",
    "    \"\"\"\n",
    "    first_prefix = string_list[0].split(\" \")[0]\n",
    "    # Create and empty dictionary\n",
    "    prefix_dict = {}\n",
    "\n",
    "    # Iterate over the list of strings\n",
    "    for string in string_list[1:]:\n",
    "        # Check if the string starts with the first prefix\n",
    "        if not string.startswith(first_prefix):\n",
    "            # If the string does not start with the first prefix, split the string and take the first word\n",
    "            first_prefix = string.split(\" \")[0]\n",
    "            if string.startswith(first_prefix):\n",
    "                # In the dictionary add the new prefix as key and the list of strings that have this prefix as value\n",
    "                prefix_dict[first_prefix] = [string for string in string_list if string.startswith(first_prefix)]\n",
    "        else:\n",
    "            # In the dictionary add the new prefix as key and the list of strings that have this prefix as value\n",
    "            prefix_dict[first_prefix] = [string for string in string_list if string.startswith(first_prefix)]\n",
    "    return prefix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid problem regarding the letters in uppercase and lowercase, convert all the letters in uppercase\n",
    "df['DESCRIZIONE'] = df['DESCRIZIONE'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function get_common_prefix to find the common prefix of the strings in the column 'DESCRIZIONE' and print the result\n",
    "\n",
    "# Crete a string list with the unique values of the column 'DESCRIZIONE'\n",
    "string_list = df['DESCRIZIONE'].unique().tolist()\n",
    "\n",
    "dict_prefix = get_common_prefix(string_list)\n",
    "for key, value in dict_prefix.items():\n",
    "    print('{}: {}'.format(key, value))\n",
    "\n",
    "# Print the number of keys in the dictionary\n",
    "print('The number of keys in the dictionary is: {}'.format(len(dict_prefix.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update some keys in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the key 'P.le' with 'P.le Roma'\n",
    "dict_prefix['P.LE ROMA'] = dict_prefix.pop('P.LE')\n",
    "# Rename the key 'F.TE' with 'F.TE NOVE'\n",
    "dict_prefix['F.TE NOVE'] = dict_prefix.pop('F.TE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the values of the dictionary with the keys 'S.' and 'San'\n",
    "print('The values of the dictionary with the key S. are: {}'.format(dict_prefix['S.']))\n",
    "print('The values of the dictionary with the key San are: {}'.format(dict_prefix['SAN']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S.Erasmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new key in the dictionary with the key S.ERASMO; insert as value the list of strings that have the prefix 'S.ERASMO'\n",
    "dict_prefix['S.ERASMO'] = [string for string in dict_prefix['S.'] if string.startswith('S.ERASMO')]\n",
    "\n",
    "# Add the value 'S. Erasmo Pu' originally in the key 'San' to the key 'S.ERASMO'\n",
    "dict_prefix['S.ERASMO'].append('S. ERASMO PU')\n",
    "\n",
    "# Remove the strings that have the prefix 'S.ERASMO' from the keys 'S.' and 'San'\n",
    "dict_prefix['S.'] = [string for string in dict_prefix['S.'] if not string.startswith('S.ERASMO')]\n",
    "dict_prefix['S.'] = [string for string in dict_prefix['S.'] if not string.startswith('S. ERASMO PU')]\n",
    "\n",
    "# Print the values of the dictionary with the key 'S.ERASMO'\n",
    "print('The values of the dictionary with the key S.ERASMO are: {}'.format(dict_prefix['S.ERASMO']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### San Marco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new key in the dictionary with the key 'San Marco'; insert as value the list of strings that have the prefix 'San Marco'\n",
    "dict_prefix['SAN MARCO'] = [string for string in dict_prefix['SAN'] if string.startswith('SAN MARCO')]\n",
    "\n",
    "\n",
    "# Add the value S. MARCO (Gi', 'S. Pietro in Gu') originally in the key 'S.' to the key 'San Marco'\n",
    "dict_prefix['SAN MARCO'].append('S. MARCO (GI')\n",
    "\n",
    "# Remove the strings that have the prefix 'San Marco' from the keys 'S.' and 'San'\n",
    "dict_prefix['SAN'] = [string for string in dict_prefix['SAN'] if not string.startswith('SAN MARCO')]\n",
    "dict_prefix['S.'] = [string for string in dict_prefix['S.'] if not string.startswith('S. MARCO (GI')]\n",
    "\n",
    "# Print the values of the dictionary with the key 'San Marco'\n",
    "print('The values of the dictionary with the key San Marco are: {}'.format(dict_prefix['SAN MARCO']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### San Dona'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new key in the dictionary with the key 'San Dona'; insert as value the list of strings that have the prefix 'San Dona'\n",
    "dict_prefix['SAN DONA'] = [string for string in dict_prefix['SAN'] if string.startswith('SAN DONA')]\n",
    "\n",
    "# Remove the strings that have the prefix 'San Dona' from the keys 'S.' and 'San'\n",
    "dict_prefix['SAN'] = [string for string in dict_prefix['SAN'] if not string.startswith('SAN DONA')]\n",
    "\n",
    "# Print the values of the dictionary with the key 'San Dona'\n",
    "print('The values of the dictionary with the key San Dona are: {}'.format(dict_prefix['SAN DONA']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### San Pietro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new key in the dictionary with the key 'San Pietro'; insert as value the list of strings that have the word 'Pietro' in the string\n",
    "dict_prefix['SAN PIETRO'] = [string for string in dict_prefix['SAN'] if 'PIETRO' in string] + [string for string in dict_prefix['S.'] if 'PIETRO' in string]\n",
    "\n",
    "# Remove the strings that have the word 'Pietro' from the keys 'S.' and 'San'\n",
    "dict_prefix['SAN'] = [string for string in dict_prefix['SAN'] if 'PIETRO' not in string]\n",
    "dict_prefix['S.'] = [string for string in dict_prefix['S.'] if 'PIETRO' not in string]\n",
    "\n",
    "# Print the values of the dictionary with the key 'San Pietro'\n",
    "print('The values of the dictionary with the key San Pietro are: {}'.format(dict_prefix['SAN PIETRO']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ca' Rossa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new key in the dictionary with the key 'Ca' Rossa'; insert as value the list of strings that have the word 'Ca' Rossa' in the string\n",
    "dict_prefix['CA\\' ROSSA'] = [string for string in dict_prefix['CA\\''] if 'CA' in string and 'ROSSA' in string]\n",
    "\n",
    "# Remove the strings that have the word 'Ca' Rossa' from the keys 'Ca''\n",
    "dict_prefix['CA\\''] = [string for string in dict_prefix['CA\\''] if 'CA' not in string or 'ROSSA' not in string]\n",
    "\n",
    "# Print the values of the dictionary with the key 'Ca Rossa'\n",
    "print('The values of the dictionary with the key Ca\\' Rossa are: {}'.format(dict_prefix['CA\\' ROSSA']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manage the remaining values in the keys 'S.' and 'San' and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage the remaining values in the keys 'S.', 'San', 'Santa', 'Sant'', 'Ca'', 'Piazza', 'Piazzale', 'Stazione', 'Treviso, 'Trento', 'Incr.'\n",
    "# Create a new key for each value in the keys as above and assign the value as value of the new key\n",
    "# Remove the values from the keys as above\n",
    "\n",
    "if 'S.' in dict_prefix:\n",
    "    for value in dict_prefix['S.']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('S.')\n",
    "\n",
    "if 'SAN' in dict_prefix:\n",
    "    for value in dict_prefix['SAN']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('SAN')\n",
    "\n",
    "if 'SANTA' in dict_prefix:\n",
    "    for value in dict_prefix['SANTA']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('SANTA')\n",
    "\n",
    "if 'SANT\\'' in dict_prefix:\n",
    "    for value in dict_prefix['SANT\\'']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('SANT\\'')\n",
    "\n",
    "if 'CA\\'' in dict_prefix:\n",
    "    for value in dict_prefix['CA\\'']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('CA\\'')\n",
    "\n",
    "if 'PIAZZA' in dict_prefix:\n",
    "    for value in dict_prefix['PIAZZA']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('PIAZZA')\n",
    "\n",
    "if 'PIAZZALE' in dict_prefix:\n",
    "    for value in dict_prefix['PIAZZALE']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('PIAZZALE')\n",
    "\n",
    "if 'VIA' in dict_prefix:\n",
    "    for value in dict_prefix['VIA']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('VIA')\n",
    "\n",
    "if 'STAZIONE' in dict_prefix:\n",
    "    for value in dict_prefix['STAZIONE']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('STAZIONE')\n",
    "\n",
    "if 'TREVISO' in dict_prefix:\n",
    "    for value in dict_prefix['TREVISO']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('TREVISO')\n",
    "\n",
    "if 'TRENTO' in dict_prefix:\n",
    "    for value in dict_prefix['TRENTO']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('TRENTO')\n",
    "\n",
    "if 'INCR.' in dict_prefix:\n",
    "    for value in dict_prefix['INCR.']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('INCR.')\n",
    "\n",
    "if 'DE' in dict_prefix:\n",
    "    for value in dict_prefix['DE']:\n",
    "        dict_prefix[value] = [value]\n",
    "    dict_prefix.pop('DE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treviso and Trento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the values Treviso, Trento, Trezzo and Treporti from the key 'Tre'\n",
    "dict_prefix['TRE'] = [string for string in dict_prefix['TRE'] if 'TREVISO' not in string and 'TRENTO' not in string and 'TREZZO' not in string and 'TREPORTI' not in string]\n",
    "\n",
    "# Print the values of the dictionary with the key 'Tre'\n",
    "print('The values of the dictionary with the key Tre are: {}'.format(dict_prefix['TRE']))\n",
    "\n",
    "# TODO: Correct the values of the keys 'Treviso' and 'Trento' with the correct values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keys with only an item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a key as only one value, then rename the key with the value\n",
    "# Use copy() to avoid RuntimeError: dictionary changed size during iteration\n",
    "for key, value in dict_prefix.copy().items():\n",
    "    if len(value) == 1:\n",
    "        dict_prefix[value[0]] = dict_prefix.pop(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, the update dictionary is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dictionary in the new format\n",
    "for key, value in dict_prefix.items():\n",
    "    print('{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dictionary in a json file\n",
    "name_file = 'dict_prefix_' + file_name.split('.')[0] + '.json'\n",
    "with open('data/dictionaries/' + name_file, 'w') as fp:\n",
    "    json.dump(dict_prefix, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe, copied from the original one\n",
    "df_new = df.copy() \n",
    "\n",
    "# Update the column 'DESCRIZIONE' of the new df with the new values of the dictionary: \n",
    "# the value that are present in the dataframe are the values of the dictionary; you have to sobstitute with the key of the dictionary\n",
    "for key, value in dict_prefix.items():\n",
    "    df_new['DESCRIZIONE'] = df_new['DESCRIZIONE'].replace(value, key)\n",
    "\n",
    "\n",
    "# Print the head of the new dataframe\n",
    "print(df_new.head())\n",
    "\n",
    "# Export the new dataframe in a txt file\n",
    "# The name of the file is dataset_cleaned followed by the name (file_name variable) of the file that has been cleaned with txt extension\n",
    "name_file = 'dataset_cleaned_' + file_name.split('.')[0] + '.txt'\n",
    "df_new.to_csv('data/processed/' + name_file, sep='\\t', index=False)\n",
    "\n",
    "print('The script has finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
