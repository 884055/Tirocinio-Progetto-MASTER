{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASTER - Notebook 3 GTFS\n",
    "## Gets geocoordinates for each stop and create a new dataset with GTFS \n",
    "### Matteo Grazioso 884055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "\n",
    "from pandas import Timestamp\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import datetime\n",
    "\n",
    "import myfunctions as mf # Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disply all columns and all rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset restriction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebbok open the dataset in which is already applied the temporal data cleaning\n",
    "\n",
    "The notebook allows you to restrict the dataset to a specific time period (e.g. before Carnival, during Carnival, after Carnival) and export the dataset in a txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_dataset_to_period(df, start_date, end_date):\n",
    "    '''\n",
    "    Restrict the dataset to only the specified period given by the user\n",
    "        :param df: the dataset to be restricted\n",
    "        :param start_date: the start date of the period\n",
    "        :param end_date: the end date of the period\n",
    "        :return: the restricted dataset        \n",
    "    ''' \n",
    "\n",
    "    # Filter the dataset to only the specified period\n",
    "    df = df[(df['DATA'] >= start_date) & (df['DATA'] <= end_date)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'data/processed/dataset_cleaned_tempesportazioneCompleta.txt'\n",
    "# path = 'data/processed/dataset_cleaned_tempvalidazioni.txt'\n",
    "# path = 'data/processed/dataset_cleaned_tempesportazionePasqua23_part1.txt'\n",
    "path = 'data/processed/dataset_cleaned_tempesportazionePasqua23_part2.txt'\n",
    "\n",
    "df = pd.read_csv(path, header=0, sep='\\t')\n",
    "\n",
    "# Save the name of the file in a variable for future use extracting the name of the file from the path\n",
    "file_name = path.split('_')[-1].split('.')[0]\n",
    "\n",
    "subfolder = file_name\n",
    "print(file_name)\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Convert the column 'DATA' to datetime format\n",
    "df['DATA'] = pd.to_datetime(df['DATA'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask in input if the user wants to restrict the analysis to a specific period (Before carnival, during carnival, after carnival)\n",
    "# If the user wants to restrict the analysis, the user has to specify the number of the period (1, 2, 3)\n",
    "# If the user doesn't want to restrict the analysis, the user has to specify the number 0\n",
    "\n",
    "if file_name == 'tempesportazioneCompleta':\n",
    "    while True:\n",
    "        input_period = input(\"Do you want to restrict the analysis to a specific period? (Yes/No) \")\n",
    "        if input_period == \"Yes\" or input_period == \"yes\" or input_period == \"Y\" or input_period == \"y\":\n",
    "            while True:\n",
    "                input_period_number = input(\"Which period do you want to restrict the analysis to? (1: Before Carnival, 2: During Carnival, 3: After Carnival) \")\n",
    "                if not input_period_number.isdigit():\n",
    "                    print(\"Enter a valid number.\")\n",
    "                    continue\n",
    "                input_period_number = int(input_period_number)\n",
    "                if input_period_number == 1:\n",
    "                    period = \"before_carnival\"\n",
    "                    break\n",
    "                elif input_period_number == 2:\n",
    "                    period = \"during_carnival\"\n",
    "                    break\n",
    "                elif input_period_number == 3:\n",
    "                    period = \"after_carnival\"\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"You have to specify a number between 1 and 3!\")\n",
    "                    continue\n",
    "            break\n",
    "        elif input_period == \"No\" or input_period == \"no\" or input_period == \"N\" or input_period == \"n\":\n",
    "            period = \"All the period\"\n",
    "            input_period_number = 0\n",
    "            break\n",
    "        else:\n",
    "            print(\"You have to specify Yes or No!\")\n",
    "            continue\n",
    "\n",
    "    if input_period_number == 1:\n",
    "        print(\"You have chosen to restrict the analysis to the period before Carnival.\")\n",
    "        print(\"Date range: 2023-01-17 to  2023-02-03\")\n",
    "        df = restrict_dataset_to_period(df, '2023-01-17', '2023-02-03')\n",
    "    elif input_period_number == 2:\n",
    "        print(\"You have chosen to restrict the analysis to the period during Carnival.\")\n",
    "        print(\"Date range: 2023-02-04 to 2023-02-21\")\n",
    "        df = restrict_dataset_to_period(df, '2023-02-04', '2023-02-21')\n",
    "    elif input_period_number == 3:\n",
    "        print(\"You have chosen to restrict the analysis to the period after Carnival.\")\n",
    "        print(\"Date range: 2023-02-22 to 2023-03-12\")\n",
    "        df = restrict_dataset_to_period(df, '2023-02-22', '2023-03-12')\n",
    "\n",
    "elif file_name == 'part1':\n",
    "    while True:\n",
    "        input_period = input(\"Do you want to restrict the analysis to a specific period? (Yes/No) \")\n",
    "        if input_period == \"Yes\" or input_period == \"yes\" or input_period == \"Y\" or input_period == \"y\":\n",
    "            while True:\n",
    "                input_period_number = input(\"Which period do you want to restrict the analysis to? (2: During Easter, 3: After Easter) \")\n",
    "                if not input_period_number.isdigit():\n",
    "                    print(\"Enter a valid number.\")\n",
    "                    continue\n",
    "                input_period_number = int(input_period_number)\n",
    "                if input_period_number == 2:\n",
    "                    period = \"during_easter\"\n",
    "                    break\n",
    "                elif input_period_number == 3:\n",
    "                    period = \"after_easter\"\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"You have to specify a number between 2 and 3!\")\n",
    "                    continue\n",
    "            break\n",
    "        elif input_period == \"No\" or input_period == \"no\" or input_period == \"N\" or input_period == \"n\":\n",
    "            period = \"All the period\"\n",
    "            input_period_number = 0\n",
    "            break\n",
    "        else:\n",
    "            print(\"You have to specify Yes or No!\")\n",
    "            continue\n",
    "\n",
    "    if input_period_number == 2:\n",
    "        print(\"You have chosen to restrict the analysis to the period during Easter.\")\n",
    "        print(\"Date range: 2023-04-04 to 2023-04-16\")\n",
    "        df = restrict_dataset_to_period(df, '2023-04-04', '2023-04-16')\n",
    "    elif input_period_number == 3:\n",
    "        print(\"You have chosen to restrict the analysis to the period after Easter.\")\n",
    "        print(\"Date range: 2023-04-17 to 2023-05-03\")\n",
    "        df = restrict_dataset_to_period(df, '2023-04-17', '2023-05-03')\n",
    "\n",
    "else:\n",
    "    period = \"All the period\"\n",
    "    print(\"You have chosen to analyse the entire period.\")\n",
    "    input_period_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print teh range of dates\n",
    "print(f\"Date range: {df['DATA'].min()} - {df['DATA'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(period)\n",
    "print(file_name)\n",
    "\n",
    "# Export the dataframe to a txt file\n",
    "# Check if the file already exists\n",
    "if input_period_number == 1 or input_period_number == 2 or input_period_number == 3:\n",
    "    if not os.path.exists('data/processed/dataset_cleaned_temp_' + period + '_' + file_name + '.txt'):\n",
    "        df.to_csv('data/processed/dataset_cleaned_temp_' + period + '_' + file_name + '.txt', sep='\\t', index=False)\n",
    "        print(\"The file has been created in the folder data/processed/dataset_cleaned_temp_\" + period + '_' + file_name + '.txt')\n",
    "    else:\n",
    "        print(\"The file already exists in the folder data/processed/dataset_cleaned_temp_\" + period + '_' + file_name + '.txt')\n",
    "        df = pd.read_csv('data/processed/dataset_cleaned_temp_' + period + '_' + file_name + '.txt', header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change same FERMATA values in order to correct the errors in the dataset (decided in a meeting on 1st September 2023)\n",
    "# Change all FERMATA 15108 to FERMATA 5108\n",
    "df['FERMATA'] = df['FERMATA'].replace(15108, 5108)\n",
    "\n",
    "# Change all FERMATA 15009 to FERMATA 5009\n",
    "df['FERMATA'] = df['FERMATA'].replace(15009, 5009)\n",
    "\n",
    "# Change all FERMATA 15049 to FERMATA 5049\n",
    "df['FERMATA'] = df['FERMATA'].replace(15049, 5049)\n",
    "\n",
    "# Change all FERMATA 15083 to FERMATA 5083\n",
    "df['FERMATA'] = df['FERMATA'].replace(15083, 5083)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file data/processed/data-GTFS/stops.txt that is a GTFS file\n",
    "stops = pd.read_csv('data/processed/data-GTFS/stops.txt', header=0, sep=',')\n",
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantain only the columns 'stop_id', 'stop_name', 'stop_lat', 'stop_lon'\n",
    "stops = stops[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']]\n",
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes df and stops on the column 'FERMATA' and 'stop_id'\n",
    "df = pd.merge(df, stops, left_on='FERMATA', right_on='stop_id', how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the column 'stop_name' is not NaN, sobstitute the value of the column 'DESCRIZIONE' with the value of the column 'stop_name' \n",
    "# because this column contains the full name of the stop while the column 'FERMATA' contains a truncated name of the stop\n",
    "df['DESCRIZIONE'] = np.where(df['stop_name'].notnull(), df['stop_name'], df['DESCRIZIONE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the column 'stop_id' and 'stop_name'\n",
    "df.drop(['stop_id', 'stop_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns in order to have the column 'stop_lat' and 'stop_lon' after the column 'DESCRIZIONE' \n",
    "df = df[['DATA', 'ORA', 'DATA_VALIDAZIONE', 'SERIALE', 'FERMATA', 'stop_lat', 'stop_lon', 'DESCRIZIONE', 'TITOLO', 'TICKET_CODE', 'DESCRIZIONE_TITOLO']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of unique values of FERMATA that have a NaN value in the column 'stop_lat' (TERRA)\n",
    "print(f\"Number of unique values of FERMATA that have a NaN value in the column 'stop_lat' (TERRA): {df[df['stop_lat'].isnull()]['FERMATA'].nunique()}\")\n",
    "\n",
    "# Print the number of unique values of FERMATA that don't have a NaN value in the column 'stop_lat' (NAVIGAZIONE VENEZIA)\n",
    "print(f\"Number of unique values of FERMATA that don't have a NaN value in the column 'stop_lat' (NAVIGAZIONE VENEZIA): {df[df['stop_lat'].notnull()]['FERMATA'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file data/processed/data-GTFS/stop_aggr.json\n",
    "with open('data/processed/data-GTFS/stop_aggr.json') as json_file:\n",
    "    stop_aggr = json.load(json_file)\n",
    "\n",
    "# Convert the key to integer\n",
    "stop_aggr = {int(k):v for k,v in stop_aggr.items()}\n",
    "\n",
    "# Stop_aggr is a dictionary with the following structure:\n",
    "# fermata:id_stop_aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop_aggr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'stop_aggr' in the dataframe df and fill it with the values of the dictionary stop_aggr\n",
    "# The key of the dictionary is the value of the column 'FERMATA' and the value of the dictionary is the value of the column 'stop_aggr'\n",
    "# Print\n",
    "df['stop_aggr'] = df['FERMATA'].map(stop_aggr)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for Murano in the column 'DESCRIZIONE'\n",
    "# df[df['DESCRIZIONE'].str.contains('Mestre Stazi')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stop_aggr as int where it is possible\n",
    "df['stop_aggr'] = df['stop_aggr'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file data/processed/data-GTFS/stop_all.json\n",
    "# stop_all is a dictionary with the following structure:\n",
    "# id_stop: description, lat, lon and I use it to fill the NaN values of the columns 'stop_lat' and 'stop_lon'\n",
    "\n",
    "with open('data/processed/data-GTFS/stop_all.json') as json_file:\n",
    "    stop_all = json.load(json_file)\n",
    "\n",
    "print(stop_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the column 'FERMATA' with the value of the column 'stop_aggr' only where the column 'stop_aggr' is different from the column 'FERMATA', otherwise leave the value of the column 'FERMATA'\n",
    "# Ignore the case where the column 'stop_aggr' is NaN\n",
    "df['FERMATA'] = np.where((df['stop_aggr'].notnull()) & (df['stop_aggr'] != df['FERMATA']), df['stop_aggr'], df['FERMATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the key to integer\n",
    "stop_all = {int(k):v for k,v in stop_all.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stop_aggr to some FERMATA values (decided in a meeting on 1st September 2023)\n",
    "# 25->-3 (Ca' Marcello), 27->-2 (Tronchetto), 28->-2 (Tronchetto), 30->-3 (Stazione Mestre),\n",
    "# 34->-4 (Aeroporto), 36->-3 (Stazione Mestre), 7777->-2 People Mover, \n",
    "\n",
    "# 4501->-5 (Klinger), 4502->-5 (Klinger), 4640->-5 (Alberoni), 4645->-5 (Klinger), 4646->-5 (Klinger), \n",
    "\n",
    "# 5075->-5 (S. Pietro in)\n",
    "\n",
    "\n",
    "df['FERMATA'] = df['FERMATA'].replace(25, -3)\n",
    "df['FERMATA'] = df['FERMATA'].replace(27, -2)\n",
    "df['FERMATA'] = df['FERMATA'].replace(28, -2)\n",
    "df['FERMATA'] = df['FERMATA'].replace(30, -3)\n",
    "df['FERMATA'] = df['FERMATA'].replace(34, -4)\n",
    "df['FERMATA'] = df['FERMATA'].replace(36, -3)\n",
    "df['FERMATA'] = df['FERMATA'].replace(7777, -2)\n",
    "df['FERMATA'] = df['FERMATA'].replace(4501, -5)\n",
    "df['FERMATA'] = df['FERMATA'].replace(4502, -5)\n",
    "df['FERMATA'] = df['FERMATA'].replace(4640, -5)\n",
    "df['FERMATA'] = df['FERMATA'].replace(4645, -5)\n",
    "df['FERMATA'] = df['FERMATA'].replace(4646, -5)\n",
    "df['FERMATA'] = df['FERMATA'].replace(5075, -5)\n",
    "\n",
    "# Where stop_aggr is null and FERMATA has one of the codes above, set stop_aggr to the value of FERMATA\n",
    "df['stop_aggr'] = np.where((df['stop_aggr'].isnull()) & (df['FERMATA'] == -3), -3, df['stop_aggr'])\n",
    "df['stop_aggr'] = np.where((df['stop_aggr'].isnull()) & (df['FERMATA'] == -2), -2, df['stop_aggr']) \n",
    "df['stop_aggr'] = np.where((df['stop_aggr'].isnull()) & (df['FERMATA'] == -4), -4, df['stop_aggr'])\n",
    "df['stop_aggr'] = np.where((df['stop_aggr'].isnull()) & (df['FERMATA'] == -5), -5, df['stop_aggr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are NaN values in the column 'stop_aggr', set FERMATA to -1 (TERRA)\n",
    "df['FERMATA'] = np.where(df['stop_aggr'].isnull(), -1, df['FERMATA'])\n",
    "\n",
    "# Where stop_aggr is null and FERMATA has -1, set stop_aggr to -1\n",
    "df['stop_aggr'] = np.where((df['stop_aggr'].isnull()) & (df['FERMATA'] == -1), -1, df['stop_aggr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are some NaN values in the column 'stop_aggr', print a warning in red, else print a message in green that all stops are mapped\n",
    "if df['stop_aggr'].isnull().sum() > 0:\n",
    "    print(\"\\033[91mWARNING: There are some NaN values in the column 'stop_aggr'!\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[92mAll stops are mapped!\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the values of 'DESCRIZIONE', 'stop_lat', 'stop_lon' with the values of the dictionary stop_all\n",
    "# The structure of the dictionary stop_all is the following:\n",
    "# fermata: [DESCRIZIONE, stop_lat, stop_lon]\n",
    "for key, value in stop_all.items():\n",
    "    df.loc[df['FERMATA'] == key, 'DESCRIZIONE'] = value[0]\n",
    "    df.loc[df['FERMATA'] == key, 'stop_lat'] = value[1]\n",
    "    df.loc[df['FERMATA'] == key, 'stop_lon'] = value[2]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the column 'stop_aggr'\n",
    "df.drop(['stop_aggr'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path of the file is something like: data/processed/dataset_cleaned_tempesportazionePasqua23_part1.txt\n",
    "# Export the dataframe to a txt file in the folder data/processed/data-GTFS/dataset_cleaned_temp_GTFS_esportazionePasqua23_part1.txt\n",
    "\n",
    "# Extract the name of the file from the path: it is all characters betwen '_temp' and '.txt'\n",
    "file_name = path.split('_temp')[-1].split('.txt')[0]\n",
    "print(file_name)\n",
    "\n",
    "# Create the path of the file\n",
    "path_export = f\"data/processed/data-GTFS/{file_name}\" + \"_GTFS.txt\"\n",
    "print(path_export)\n",
    "\n",
    "# Export the dataframe to a txt file in the folder data/processed/data-GTFS/\n",
    "df.to_csv(path_export, sep='\\t', index=False)\n",
    "print(f\"File exported to {path_export}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
