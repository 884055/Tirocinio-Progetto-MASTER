{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASTER - Notebook 4\n",
    "## Hierarchical clustering with second procedure\n",
    "### Matteo Grazioso 884055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import folium\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import myfunctions as mf # Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disply all columns and all rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset that has also the geo coordinates\n",
    "# Find all txt files in the data folder\n",
    "txt_file = mf.find_txt_files('data/processed/data-GTFS')\n",
    "\n",
    "# From the list of txt files, remove the files that don't contain geo coordinates that are all json files and stops.txt\n",
    "for file in txt_file:\n",
    "    if file.endswith('stops.txt'):\n",
    "        txt_file.remove(file)\n",
    "    elif file.endswith('.json'):\n",
    "        txt_file.remove(file)\n",
    "\n",
    "print(\"Select a dataset with geo coordinates from the list:\")\n",
    "\n",
    "# Choose a dataset from the list of txt files\n",
    "selected_dataset = mf.choose_dataset(txt_file)\n",
    "\n",
    "if selected_dataset:\n",
    "    print(f\"You selected the dataset {selected_dataset}\")\n",
    "else:\n",
    "    print(\"No dataset selected.\")\n",
    "\n",
    "path  = selected_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, header=0, sep='\\t')\n",
    "\n",
    "# Save the name of the file in a variable for future use extracting the name of the file from the path\n",
    "file_name = path.split('/')[3]\n",
    "file_name = file_name.split('.')[0]\n",
    "\n",
    "subfolder = file_name\n",
    "print(f\"File name: {file_name}\")\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "df.head()\n",
    "\n",
    "# Convert the column 'DATA' to datetime format\n",
    "df['DATA'] = pd.to_datetime(df['DATA'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the interval of dates for which we have data\n",
    "print('Date range: {} to {}'.format(df['DATA'].min(), df['DATA'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename stop_lat to LONGITUDE and stop_lon to LATITUDE\n",
    "df.rename(columns={'stop_lat': 'LATITUDE', 'stop_lon': 'LONGITUDE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of unique values of the column 'FERMATA'\n",
    "print('Number of unique values of the column FERMATA: {}'.format(df['FERMATA'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each stop, store the number of use for each ticket code\n",
    "# Each stop is a point identified by the coordinates (latitude, longitude)\n",
    "\n",
    "with open('data/dictionaries/dict_ticket_codes.json') as f:\n",
    "        ticket_codes = json.load(f)\n",
    "\n",
    "print('The ticket codes are: ', ticket_codes)\n",
    "\n",
    "# Change 5-STUD, 6-STUD to STUD in the dataframe\n",
    "df['TICKET_CODE'] = df['TICKET_CODE'].replace(['5-STUD', '6-STUD'], 'STUD')\n",
    "# Change 5-WKRS, 6-WKRS to WKRS in the dataframe\n",
    "df['TICKET_CODE'] = df['TICKET_CODE'].replace(['5-WKRS', '6-WKRS'], 'WKRS')\n",
    "# Change 5-RET, 6-RET to RET in the dataframe\n",
    "df['TICKET_CODE'] = df['TICKET_CODE'].replace(['5-RET', '6-RET'], 'RET')\n",
    "\n",
    "# Print the unique ticket codes\n",
    "# Print information about the changes made\n",
    "print('The ticket codes 5-STUD and 6-STUD have been changed to STUD')\n",
    "print('The ticket codes 5-WKRS and 6-WKRS have been changed to WKRS')\n",
    "print('The ticket codes 5-RET and 6-RET have been changed to RET')\n",
    "\n",
    "# Convert all the ticket codes to string\n",
    "df['TICKET_CODE'] = df['TICKET_CODE'].astype(str)\n",
    "\n",
    "ticket_codes = df['TICKET_CODE'].unique()\n",
    "# Sort the ticket codes\n",
    "ticket_codes.sort()\n",
    "\n",
    "print('The considered ticket codes are: ', ticket_codes)\n",
    "\n",
    "# For each stop, store the number of visits for each ticket code\n",
    "# Iterate over the stops dataframe and for each stop, store the number of visits for each ticket code\n",
    "# Notice that a stop is a pair of coordinates (latitude, longitude)\n",
    "\n",
    "# The columns of the dataframe are:\n",
    "# ['DATA', 'ORA', 'DATA_VALIDAZIONE', 'SERIALE', 'FERMATA', 'DESCRIZIONE',\n",
    "#        'TITOLO', 'TICKET_CODE', 'DESCRIZIONE_TITOLO', 'LATITUDE', 'LONGITUDE']\n",
    "\n",
    "# Create a dataframe of stops\n",
    "df_stop = df[['LATITUDE', 'LONGITUDE', 'TICKET_CODE', 'FERMATA', 'DESCRIZIONE']]\n",
    "\n",
    "df_stop.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop_count = df_stop.groupby(['LATITUDE', 'LONGITUDE', 'TICKET_CODE', 'FERMATA', 'DESCRIZIONE']).size().reset_index(name='COUNT')\n",
    "\n",
    "df_stop_count.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the column COUNT\n",
    "df_stop_count['COUNT'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table for the ticket codes but maintaining the information about the stops\n",
    "df_stop_count = df_stop_count.pivot_table(index=['LATITUDE', 'LONGITUDE', 'FERMATA', 'DESCRIZIONE'], columns='TICKET_CODE', values='COUNT', fill_value=0)\n",
    "df_stop_count.reset_index(inplace=True)\n",
    "\n",
    "# For each stop (LATITUDE, LONGITUDE), change the counter of each ticket code as a percentage of the total number of tickets\n",
    "for row in range(len(df_stop_count)):\n",
    "    total = df_stop_count.iloc[row, 4:].sum()\n",
    "    for col in range(4, len(df_stop_count.columns)):\n",
    "        df_stop_count.iloc[row, col] = df_stop_count.iloc[row, col] / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def haversine_distance(coord1, coord2):\n",
    "    \"\"\"\n",
    "        Calculate the distance between two points on Earth using the haversine formula.\n",
    "        The haversine formula determines the great-circle distance between two points on a sphere given their longitudes and latitudes.\n",
    "        The haversin formula is specified as:\n",
    "            a = sin²(Δlat/2) + cos(lat1).cos(lat2).sin²(Δlong/2)\n",
    "            c = 2.atan2(√a, √(1−a))\n",
    "            d = R.c\n",
    "        where:\n",
    "            lat1, long1 = Latitude and Longitude of point 1 (in decimal degrees)\n",
    "            lat2, long2 = Latitude and Longitude of point 2 (in decimal degrees)\n",
    "            R = Radius of the Earth in kilometers\n",
    "            Δlat = lat2− lat1\n",
    "            Δlong = long2− long1\n",
    "\n",
    "        :param coord1: Tuple of (latitude, longitude) for point 1\n",
    "        :param coord2: Tuple of (latitude, longitude) for point 2\n",
    "        :return: Distance between the two coordinates in kilometers\n",
    "    \"\"\"\n",
    "    lon1, lat1 = coord1\n",
    "    lon2, lat2 = coord2\n",
    "    \n",
    "    R = 6371  # Radius of the Earth in kilometers\n",
    "    \n",
    "    # Convert decimal degrees to radians\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    \n",
    "    # Apply haversine formula\n",
    "    # a = sin²(Δlat/2) + cos(lat1).cos(lat2).sin²(Δlong/2)\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon / 2) ** 2\n",
    "\n",
    "    # c = 2.atan2(√a, √(1−a))\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    \n",
    "    # d = R.c\n",
    "    distance = R * c\n",
    "\n",
    "    # print('Distance between stops: ', distance)\n",
    "    return distance\n",
    "\n",
    "def cosine_similarity_distance(counts1, counts2):\n",
    "    # Calculate cosine similarity between two count vectors\n",
    "    \"\"\"\n",
    "        Calculate the cosine similarity between two count vectors.\n",
    "        The cosine similarity is a measure of similarity between two non-zero vectors of an inner product space \n",
    "        that measures the cosine of the angle between them.\n",
    "        The cosine of 0° is 1, and it is less than 1 for any other angle.\n",
    "        It is thus a judgement of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1,\n",
    "        two vectors at 90° have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude.\n",
    "        The cosine similarity is particularly used in positive space, where the outcome is neatly bounded in [0,1].\n",
    "        The cosine similarity is mathematically defined as:\n",
    "            cos(θ) = A.B / ||A||.||B||\n",
    "        where:\n",
    "            A.B = Dot product of A and B\n",
    "            ||A|| = Euclidean norm of A\n",
    "            ||B|| = Euclidean norm of B\n",
    "        :param counts1: List of counts for each ticket code for stop 1\n",
    "        :param counts2: List of counts for each ticket code for stop 2\n",
    "        :return: Cosine similarity between the two count vectors\n",
    "\n",
    "        # This function calls the cosine_similarity function from sklearn.metrics.pairwise to calculate the cosine similarity between two count vectors.\n",
    "    \"\"\"\n",
    "    similarity_matrix = cosine_similarity([counts1], [counts2])\n",
    "    similarity = 1 - similarity_matrix[0][0]\n",
    "    \n",
    "    # print('Similarity between stops: ', similarity)\n",
    "    return similarity\n",
    "\n",
    "def custom_distance(stop1, stop2, coord_weight, similarity_weight):\n",
    "    \"\"\"\n",
    "        Calculate the custom distance between two stops.\n",
    "        The custom distance is a weighted combination of the haversine distance between the two stops and the cosine similarity between the two stops.\n",
    "        The custom distance is mathematically defined as:\n",
    "            custom_distance = coord_weight * haversine_distance + similarity_weight * cosine_similarity_distance\n",
    "        where:\n",
    "            coord_weight = Weight for haversine distance\n",
    "            similarity_weight = Weight for cosine similarity distance\n",
    "        :param stop1: Tuple of (latitude, longitude, counts for each ticket code) for stop 1\n",
    "        :param stop2: Tuple of (latitude, longitude, counts for each ticket code) for stop 2\n",
    "        :param coord_weight: Weight for haversine distance\n",
    "        :param similarity_weight: Weight for cosine similarity distance\n",
    "        :return: Custom distance between the two stops\n",
    "    \"\"\"\n",
    "    # Calculate distances\n",
    "    # Calculate haversine distance between two stops\n",
    "    coord_distance = haversine_distance((stop1[0], stop1[1]), (stop2[0], stop2[1]))\n",
    "    # Calculate cosine similarity between two stops\n",
    "    count_similarity = cosine_similarity_distance(stop1[4:], stop2[4:]) # CAMBIATO PERCHÉ NON C'È LA COLONNA 'FERMATA' e 'DESCRIZIONE'\n",
    "    \n",
    "    # Combine distances with appropriate weights\n",
    "    combined_distance = coord_weight * coord_distance + similarity_weight * count_similarity\n",
    "    return combined_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From df_stop_count remove descrizione\n",
    "df_stop_count = df_stop_count.drop(columns=['DESCRIZIONE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_count_stop is a df with columns [' LATITUDE ', ' LONGITUDE ', '1', '2', '3', '4', '5', '6', '7', 'STUD', 'RET', 'WKRS'] \n",
    "data = df_stop_count.values \n",
    "# print(data)\n",
    "\n",
    "# Custom distance function parameters\n",
    "coord_weight = 0.3\n",
    "similarity_weight = 0.7\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "# Calculate linkage matrix using custom distance function\n",
    "# The custom distance function is a weighted average of the haversine distance between coordinates and the similarity between the stop counts\n",
    "linkage_matrix = linkage(data, method='single', metric=lambda x, y: custom_distance(x, y, coord_weight, similarity_weight))\n",
    "\n",
    "# Create a dendrogram for visualization purposes \n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(linkage_matrix, truncate_mode='lastp', p=12, leaf_rotation=90., leaf_font_size=10., show_contracted=True)\n",
    "\n",
    "# Determine clusters based on a desired threshold or number of clusters\n",
    "threshold = 0.25\n",
    "clusters = fcluster(linkage_matrix, t=threshold, criterion='distance', depth=2, R=None, monocrit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding cluster labels to the stop count dataframe\n",
    "df_stop_count['Cluster'] = clusters\n",
    "print(df_stop_count.shape)\n",
    "df_stop_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hex codes of tab_20 palette in the format 1:hex_code dict\n",
    "cluster_colors = dict(zip(range(1,51), sns.color_palette(\"tab20\", 50).as_hex()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of cluster distribution \n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='Cluster', data=df_stop_count, palette=cluster_colors)\n",
    "plt.yticks(np.arange(0, max(df_stop_count['Cluster'].value_counts()) + 5, 2))\n",
    "plt.title('Cluster Distribution: ' + 'date range: ' + str(df['DATA'].min().date()) + ' to ' + str(df['DATA'].max().date()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folium map centered around the mean latitude and longitude\n",
    "center_lat = np.mean(df_stop_count['LATITUDE'])\n",
    "center_lon = np.mean(df_stop_count['LONGITUDE'])\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=12)\n",
    "\n",
    "# Create markers for each stop and color them based on clusters\n",
    "for idx, row in df_stop_count.iterrows():\n",
    "    # Retrieve Cluster id and set it as a integer\n",
    "    cluster = int(row['Cluster'])\n",
    "\n",
    "    cluster_color = cluster_colors.get(cluster, 'gray')  # Default to gray if cluster color is not defined\n",
    "\n",
    "    # cluster_color = cluster_\n",
    "    # colors.get(cluster, 'gray')  # Default to gray if cluster color is not defined\n",
    "    # Add a label to the marker with the name of the stop contained in the column 'DESCRIZIONE'\n",
    "    # Retrieve the name of the stop from the column 'DESCRIZIONE' of the dataframe df matching the FERMATA\n",
    "    location = df[df['FERMATA'] == row['FERMATA']]['DESCRIZIONE'].values[0]\n",
    "    # Retrieve FERMATA id and set it as a integer\n",
    "    fermata = int(row['FERMATA'])\n",
    "    # Retrieve Cluster id and set it as a integer\n",
    "    cluster = int(row['Cluster'])\n",
    "\n",
    "    # Create a string for popup message containing the name of the stop, FERMATA and the cluster in BOLD\n",
    "    popup_message = f\"<b><i>{location}</i></b><br><br><u>Fermata:</u> {fermata}<br><u>Cluster:</u> {cluster}\"\n",
    "\n",
    "    # Add a marker to the map with the popup message and the color of the cluster\n",
    "    # folium.Marker(location=[row['LATITUDE'], row['LONGITUDE']], popup=popup_message, icon=folium.Icon(color=cluster_color)).add_to(m)\n",
    "    if fermata < 0:\n",
    "        folium.Marker(location=[row['LATITUDE'], row['LONGITUDE']], popup=popup_message, icon=folium.Icon(color='white', icon_color=cluster_color, icon='bus', prefix='fa')).add_to(m)\n",
    "    else:\n",
    "        folium.Marker(location=[row['LATITUDE'], row['LONGITUDE']], popup=popup_message, icon=folium.Icon(color='white', icon_color=cluster_color, icon='ship', prefix='fa')).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of unique values of the column 'FERMATA'\n",
    "print('Number of unique values of the column FERMATA: {}'.format(df['FERMATA'].nunique()))\n",
    "# print the numer of clusters\n",
    "print('Number of clusters: {}'.format(df_stop_count['Cluster'].nunique()))\n",
    "# Print the average number of stops per cluster\n",
    "print('Average number of stops per cluster: {}'.format(df_stop_count['Cluster'].value_counts().mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each Cluster id, print the number of stops in that cluster, the FERMATA id and the name of the stop\n",
    "df_stop_count_copy = df_stop_count.copy()\n",
    "# To df_stop_count add a column with the name of the stop matching the FERMATA\n",
    "df_stop_count_copy['DESCRIZIONE'] = df_stop_count_copy['FERMATA'].apply(lambda x: df[df['FERMATA'] == x]['DESCRIZIONE'].values[0])\n",
    "\n",
    "# Consider only the columns ['Cluster', 'FERMATA', 'DESCRIZIONE']\n",
    "df_stop_count_copy = df_stop_count_copy[['Cluster', 'FERMATA', 'DESCRIZIONE']]\n",
    "df_stop_count_copy.columns.name = None\n",
    "df_stop_count_copy.head()\n",
    "\n",
    "print('Number of clusters: ', max(df_stop_count_copy['Cluster']))\n",
    "print('\\n')\n",
    "for cluster in range(1, max(df_stop_count_copy['Cluster']) + 1):\n",
    "    print(f\"Cluster {cluster} contains {len(df_stop_count_copy[df_stop_count_copy['Cluster'] == cluster])} stops.\")\n",
    "    print(df_stop_count_copy[df_stop_count_copy['Cluster'] == cluster][['FERMATA', 'DESCRIZIONE']])\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the map to an HTML file\n",
    "# Import the necessary libraries\n",
    "from datetime import datetime\n",
    "time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "try:\n",
    "    m.save('map/' + file_name + '_clustered_' + time + '.html')\n",
    "    print('Map saved in map/' + file_name + '/' + file_name + '_clustered_' + time + '.html')\n",
    "except:\n",
    "    # Create a new folder in map folder\n",
    "    os.mkdir('map/' + file_name)\n",
    "    m.save('map/' + file_name + '/' + file_name + '_clustered_' + time + '.html')\n",
    "    print('Map saved in map/' + file_name + '/' + file_name + '_clustered_' + time + '.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply hierarchical clustering to the data of the main island of Venice (the most populated cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the data of the main island of Venice (the cluster most populated)\n",
    "cluster_main_island = df_stop_count['Cluster'].value_counts().index[0]\n",
    "\n",
    "print('The cluster with the highest number of stops is the cluster number', cluster_main_island)\n",
    "\n",
    "cluster_main_island = df_stop_count[df_stop_count['Cluster'] == cluster_main_island]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_main_island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply hierarchical clustering to the data of the main island of Venice (the most populated one)\n",
    "\n",
    "data = cluster_main_island.values\n",
    "\n",
    "# Custom distance function parameters\n",
    "coord_weight = 0.3\n",
    "similarity_weight = 0.7\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "# Calculate linkage matrix using custom distance function\n",
    "# The custom distance function is a weighted average of the haversine distance between coordinates and the similarity between the stop counts\n",
    "linkage_matrix = linkage(data, method='single', metric=lambda x, y: custom_distance(x, y, coord_weight, similarity_weight))\n",
    "\n",
    "# Create a dendrogram for visualization purposes \n",
    "dendrogram(linkage_matrix, truncate_mode='lastp', p=12, leaf_rotation=90., leaf_font_size=10., show_contracted=True)\n",
    "\n",
    "# Determine clusters based on a desired threshold or number of clusters\n",
    "threshold = 0.25\n",
    "clusters = fcluster(linkage_matrix, t=threshold, criterion='distance', depth=2, R=None, monocrit=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_main_island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_main_island['Cluster'] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folium map centered around the mean latitude and longitude\n",
    "center_lat = np.mean(cluster_main_island['LATITUDE'])\n",
    "center_lon = np.mean(cluster_main_island['LONGITUDE'])\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=12)\n",
    "\n",
    "# Create markers for each stop and color them based on clusters\n",
    "for idx, row in cluster_main_island.iterrows():\n",
    "    # Retrieve Cluster id and set it as a integer\n",
    "    cluster = int(row['Cluster'])\n",
    "\n",
    "    cluster_color = cluster_colors.get(cluster, 'gray')  # Default to gray if cluster color is not defined\n",
    "\n",
    "    # cluster_color = cluster_\n",
    "    # colors.get(cluster, 'gray')  # Default to gray if cluster color is not defined\n",
    "    # Add a label to the marker with the name of the stop contained in the column 'DESCRIZIONE'\n",
    "    # Retrieve the name of the stop from the column 'DESCRIZIONE' of the dataframe df matching the FERMATA\n",
    "    location = df[df['FERMATA'] == row['FERMATA']]['DESCRIZIONE'].values[0]\n",
    "    # Retrieve FERMATA id and set it as a integer\n",
    "    fermata = int(row['FERMATA'])\n",
    "    # Retrieve Cluster id and set it as a integer\n",
    "    cluster = int(row['Cluster'])\n",
    "\n",
    "    # Create a string for popup message containing the name of the stop, FERMATA and the cluster in BOLD\n",
    "    popup_message = f\"<b><i>{location}</i></b><br><br><u>Fermata:</u> {fermata}<br><u>Cluster:</u> {cluster}\"\n",
    "\n",
    "    # Add a marker to the map with the popup message and the color of the cluster\n",
    "    # folium.Marker(location=[row['LATITUDE'], row['LONGITUDE']], popup=popup_message, icon=folium.Icon(color=cluster_color)).add_to(m)\n",
    "    if fermata < 0:\n",
    "        folium.Marker(location=[row['LATITUDE'], row['LONGITUDE']], popup=popup_message, icon=folium.Icon(color='white', icon_color=cluster_color, icon='bus', prefix='fa')).add_to(m)\n",
    "    else:\n",
    "        folium.Marker(location=[row['LATITUDE'], row['LONGITUDE']], popup=popup_message, icon=folium.Icon(color='white', icon_color=cluster_color, icon='ship', prefix='fa')).add_to(m)\n",
    "\n",
    "\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
