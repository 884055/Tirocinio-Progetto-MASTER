{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASTER - Notebook 4\n",
    "## Hierarchical clustering with second procedure\n",
    "### Matteo Grazioso 884055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import folium\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import myfunctions as mf # Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disply all columns and all rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_dataset_to_period(df, start_date, end_date):\n",
    "    '''\n",
    "    Restrict the dataset to only the specified period given by the user\n",
    "        :param df: the dataset to be restricted\n",
    "        :param start_date: the start date of the period\n",
    "        :param end_date: the end date of the period\n",
    "        :return: the restricted dataset        \n",
    "    ''' \n",
    "\n",
    "    # Filter the dataset to only the specified period\n",
    "    df = df[(df['DATA'] >= start_date) & (df['DATA'] <= end_date)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebbok open the dataset esportazioneCompleta in which is already applied the temporal data cleaning\n",
    "# The notebook allows you to restrict the dataset to a specific time period (before Carnival, during Carnival, after Carnival) and export the dataset in a txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'data/processed/dataset_cleaned_tempesportazioneCompleta.txt'\n",
    "# path = 'data/processed/dataset_cleaned_tempvalidazioni.txt'\n",
    "# path = 'data/processed/dataset_cleaned_tempesportazionePasqua23_part1.txt'\n",
    "path = 'data/processed/dataset_cleaned_tempesportazionePasqua23_part2.txt'\n",
    "\n",
    "df = pd.read_csv(path, header=0, sep='\\t')\n",
    "\n",
    "# Save the name of the file in a variable for future use extracting the name of the file from the path\n",
    "file_name = path.split('_')[-1].split('.')[0]\n",
    "\n",
    "subfolder = file_name\n",
    "print(file_name)\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Convert the column 'DATA' to datetime format\n",
    "df['DATA'] = pd.to_datetime(df['DATA'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask in input if the user wants to restrict the analysis to a specific period (Before carnival, during carnival, after carnival)\n",
    "# If the user wants to restrict the analysis, the user has to specify the number of the period (1, 2, 3)\n",
    "# If the user doesn't want to restrict the analysis, the user has to specify the number 0\n",
    "\n",
    "if file_name == 'tempesportazioneCompleta':\n",
    "    while True:\n",
    "        input_period = input(\"Do you want to restrict the analysis to a specific period? (Yes/No) \")\n",
    "        if input_period == \"Yes\" or input_period == \"yes\" or input_period == \"Y\" or input_period == \"y\":\n",
    "            while True:\n",
    "                input_period_number = input(\"Which period do you want to restrict the analysis to? (1: Before Carnival, 2: During Carnival, 3: After Carnival) \")\n",
    "                if not input_period_number.isdigit():\n",
    "                    print(\"Enter a valid number.\")\n",
    "                    continue\n",
    "                input_period_number = int(input_period_number)\n",
    "                if input_period_number == 1:\n",
    "                    period = \"before_carnival\"\n",
    "                    break\n",
    "                elif input_period_number == 2:\n",
    "                    period = \"during_carnival\"\n",
    "                    break\n",
    "                elif input_period_number == 3:\n",
    "                    period = \"after_carnival\"\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"You have to specify a number between 1 and 3!\")\n",
    "                    continue\n",
    "            break\n",
    "        elif input_period == \"No\" or input_period == \"no\" or input_period == \"N\" or input_period == \"n\":\n",
    "            period = \"All the period\"\n",
    "            input_period_number = 0\n",
    "            break\n",
    "        else:\n",
    "            print(\"You have to specify Yes or No!\")\n",
    "            continue\n",
    "\n",
    "    if input_period_number == 1:\n",
    "        print(\"You have chosen to restrict the analysis to the period before Carnival.\")\n",
    "        print(\"Date range: 2023-01-17 to  2023-02-03\")\n",
    "        df = restrict_dataset_to_period(df, '2023-01-17', '2023-02-03')\n",
    "    elif input_period_number == 2:\n",
    "        print(\"You have chosen to restrict the analysis to the period during Carnival.\")\n",
    "        print(\"Date range: 2023-02-04 to 2023-02-21\")\n",
    "        df = restrict_dataset_to_period(df, '2023-02-04', '2023-02-21')\n",
    "    elif input_period_number == 3:\n",
    "        print(\"You have chosen to restrict the analysis to the period after Carnival.\")\n",
    "        print(\"Date range: 2023-02-22 to 2023-03-12\")\n",
    "        df = restrict_dataset_to_period(df, '2023-02-22', '2023-03-12')\n",
    "\n",
    "elif file_name == 'part1':\n",
    "    while True:\n",
    "        input_period = input(\"Do you want to restrict the analysis to a specific period? (Yes/No) \")\n",
    "        if input_period == \"Yes\" or input_period == \"yes\" or input_period == \"Y\" or input_period == \"y\":\n",
    "            while True:\n",
    "                input_period_number = input(\"Which period do you want to restrict the analysis to? (2: During Easter, 3: After Easter) \")\n",
    "                if not input_period_number.isdigit():\n",
    "                    print(\"Enter a valid number.\")\n",
    "                    continue\n",
    "                input_period_number = int(input_period_number)\n",
    "                if input_period_number == 2:\n",
    "                    period = \"during_easter\"\n",
    "                    break\n",
    "                elif input_period_number == 3:\n",
    "                    period = \"after_easter\"\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"You have to specify a number between 2 and 3!\")\n",
    "                    continue\n",
    "            break\n",
    "        elif input_period == \"No\" or input_period == \"no\" or input_period == \"N\" or input_period == \"n\":\n",
    "            period = \"All the period\"\n",
    "            input_period_number = 0\n",
    "            break\n",
    "        else:\n",
    "            print(\"You have to specify Yes or No!\")\n",
    "            continue\n",
    "\n",
    "    if input_period_number == 2:\n",
    "        print(\"You have chosen to restrict the analysis to the period during Easter.\")\n",
    "        print(\"Date range: 2023-04-04 to 2023-04-16\")\n",
    "        df = restrict_dataset_to_period(df, '2023-04-04', '2023-04-16')\n",
    "    elif input_period_number == 3:\n",
    "        print(\"You have chosen to restrict the analysis to the period after Easter.\")\n",
    "        print(\"Date range: 2023-04-17 to 2023-05-03\")\n",
    "        df = restrict_dataset_to_period(df, '2023-04-17', '2023-05-03')\n",
    "\n",
    "else:\n",
    "    period = \"All the period\"\n",
    "    print(\"You have chosen to analyse the entire period.\")\n",
    "    input_period_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(period)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe to a txt file\n",
    "# Check if the file already exists\n",
    "if input_period_number == 1 or input_period_number == 2 or input_period_number == 3:\n",
    "    if not os.path.exists('data/processed/dataset_cleaned_temp_' + period + '_' + file_name + '.txt'):\n",
    "        df.to_csv('data/processed/dataset_cleaned_temp_' + period + '_' + file_name + '.txt', sep='\\t', index=False)\n",
    "        print(\"The file has been created in the folder data/processed/dataset_cleaned_temp_\" + period + '_' + file_name + '.txt')\n",
    "    else:\n",
    "        print(\"The file already exists in the folder data/processed/dataset_cleaned_temp_\" + period + '_' + file_name + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the code in Notebook3AUX.py that has the aim to get geocoordinates for each stop and create a new dataset in csv format.\n",
    "# If in the folder data/processed/temp_2-esportazioneCompleta doesn't exist a file whose name contains the content of the variable period, then execute the code in Notebook3AUX.py\n",
    "if file_name == 'tempesportazioneCompleta':\n",
    "    list = os.listdir(\"data/processed/temp_tempesportazioneCompleta\")\n",
    "elif file_name == \"tempvalidazioni\":\n",
    "    list = os.listdir(\"data/processed/temp_tempvalidazioni\")\n",
    "elif file_name == \"part1\" or file_name == \"part2\":\n",
    "    list = os.listdir(\"data/processed/temp_esportazioneCompleta23\")\n",
    "else:\n",
    "    list = \"None\"\n",
    "check = False\n",
    "for name in list:\n",
    "    if period in name:\n",
    "        if file_name == \"part1\" or file_name == \"part2\":\n",
    "            if file_name in name:\n",
    "                print(\"File already exists: \" + name)\n",
    "                check = True\n",
    "                break\n",
    "        else:\n",
    "            print(\"File already exists: \" + name)\n",
    "            check = True\n",
    "            break\n",
    "\n",
    "if check == False:\n",
    "    print(\"The file with the geocoordinates for the period \" + period + \" doesn't exist. It will be created.\")\n",
    "    print(\"This operation could take a while...\")\n",
    "    print(\"\\n \\n\\033[91mPlese, digit the number of the period you want to analyze: \" + period + \"\\033[0m\")\n",
    "    with open(\"Notebook3AUX.py\", \"r\") as file:\n",
    "        code = file.read()\n",
    "        exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset that has also the geo coordinates\n",
    "# Find all txt files in the data folder\n",
    "csv_file = mf.find_csv_files('data/processed/')\n",
    "\n",
    "print(\"Select a dataset with geo coordinates from the list:\")\n",
    "\n",
    "# Choose a dataset from the list of txt files\n",
    "selected_dataset = mf.choose_dataset(csv_file)\n",
    "\n",
    "if selected_dataset:\n",
    "    print(f\"You selected the dataset {selected_dataset}\")\n",
    "else:\n",
    "    print(\"No dataset selected.\")\n",
    "\n",
    "path  = selected_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, header=0, sep=',')\n",
    "\n",
    "# Save the name of the file in a variable for future use extracting the name of the file from the path\n",
    "file_name = path.split('_')[1]\n",
    "# If file_name has a slash, split it and take the first element\n",
    "if '/' in file_name:\n",
    "    file_name = file_name.split('/')[0]\n",
    "subfolder = file_name\n",
    "print(f\"File name: {file_name}\")\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "df.head()\n",
    "\n",
    "# Convert the column 'DATA' to datetime format\n",
    "df['DATA'] = pd.to_datetime(df['DATA'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the interval of dates for which we have data\n",
    "print('Date range: {} to {}'.format(df['DATA'].min(), df['DATA'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each stop, store the number of use for each ticket code\n",
    "# Each stop is a point identified by the coordinates (latitude, longitude)\n",
    "\n",
    "with open('data/dictionaries/dict_ticket_codes.json') as f:\n",
    "        ticket_codes = json.load(f)\n",
    "\n",
    "print('The ticket codes are: ', ticket_codes)\n",
    "\n",
    "# Change 5-STUD, 6-STUD to STUD in the dataframe\n",
    "df['TICKET_CODE'] = df['TICKET_CODE'].replace(['5-STUD', '6-STUD'], 'STUD')\n",
    "# Change 5-WKRS, 6-WKRS to WKRS in the dataframe\n",
    "df['TICKET_CODE'] = df['TICKET_CODE'].replace(['5-WKRS', '6-WKRS'], 'WKRS')\n",
    "# Change 5-RET, 6-RET to RET in the dataframe\n",
    "df['TICKET_CODE'] = df['TICKET_CODE'].replace(['5-RET', '6-RET'], 'RET')\n",
    "\n",
    "# Print the unique ticket codes\n",
    "# Print information about the changes made\n",
    "print('The ticket codes 5-STUD and 6-STUD have been changed to STUD')\n",
    "print('The ticket codes 5-WKRS and 6-WKRS have been changed to WKRS')\n",
    "print('The ticket codes 5-RET and 6-RET have been changed to RET')\n",
    "\n",
    "# Convert all the ticket codes to string\n",
    "df['TICKET_CODE'] = df['TICKET_CODE'].astype(str)\n",
    "\n",
    "ticket_codes = df['TICKET_CODE'].unique()\n",
    "# Sort the ticket codes\n",
    "ticket_codes.sort()\n",
    "\n",
    "print('The considered ticket codes are: ', ticket_codes)\n",
    "\n",
    "# For each stop, store the number of visits for each ticket code\n",
    "# Iterate over the stops dataframe and for each stop, store the number of visits for each ticket code\n",
    "# Notice that a stop is a pair of coordinates (latitude, longitude)\n",
    "\n",
    "# The columns of the dataframe are:\n",
    "# ['DATA', 'ORA', 'DATA_VALIDAZIONE', 'SERIALE', 'FERMATA', 'DESCRIZIONE',\n",
    "#        'TITOLO', 'TICKET_CODE', 'DESCRIZIONE_TITOLO', 'LATITUDE', 'LONGITUDE']\n",
    "\n",
    "# Create a dataframe of stops\n",
    "df_stop = df[['LATITUDE', 'LONGITUDE', 'TICKET_CODE']]\n",
    "\n",
    "df_stop.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop_count = df_stop.groupby(['LATITUDE', 'LONGITUDE', 'TICKET_CODE']).size().reset_index(name='COUNT')\n",
    "\n",
    "df_stop_count.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the column COUNT\n",
    "df_stop_count['COUNT'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table for the ticket codes\n",
    "df_stop_count = df_stop_count.pivot_table(index=['LATITUDE', 'LONGITUDE'], columns='TICKET_CODE', values='COUNT', fill_value=0)\n",
    "df_stop_count.reset_index(inplace=True)\n",
    "\n",
    "# For each stop (LATITUDE, LONGITUDE), change the counter of each ticket code as a percentage of the total number of tickets\n",
    "for row in range(len(df_stop_count)):\n",
    "    total = df_stop_count.iloc[row, 2:].sum()\n",
    "    for col in range(2, len(df_stop_count.columns)):\n",
    "        df_stop_count.iloc[row, col] = df_stop_count.iloc[row, col] / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def haversine_distance(coord1, coord2):\n",
    "    \"\"\"\n",
    "        Calculate the distance between two points on Earth using the haversine formula.\n",
    "        The haversine formula determines the great-circle distance between two points on a sphere given their longitudes and latitudes.\n",
    "        The haversin formula is specified as:\n",
    "            a = sin²(Δlat/2) + cos(lat1).cos(lat2).sin²(Δlong/2)\n",
    "            c = 2.atan2(√a, √(1−a))\n",
    "            d = R.c\n",
    "        where:\n",
    "            lat1, long1 = Latitude and Longitude of point 1 (in decimal degrees)\n",
    "            lat2, long2 = Latitude and Longitude of point 2 (in decimal degrees)\n",
    "            R = Radius of the Earth in kilometers\n",
    "            Δlat = lat2− lat1\n",
    "            Δlong = long2− long1\n",
    "\n",
    "        :param coord1: Tuple of (latitude, longitude) for point 1\n",
    "        :param coord2: Tuple of (latitude, longitude) for point 2\n",
    "        :return: Distance between the two coordinates in kilometers\n",
    "    \"\"\"\n",
    "    lon1, lat1 = coord1\n",
    "    lon2, lat2 = coord2\n",
    "    \n",
    "    R = 6371  # Radius of the Earth in kilometers\n",
    "    \n",
    "    # Convert decimal degrees to radians\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    \n",
    "    # Apply haversine formula\n",
    "    # a = sin²(Δlat/2) + cos(lat1).cos(lat2).sin²(Δlong/2)\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon / 2) ** 2\n",
    "\n",
    "    # c = 2.atan2(√a, √(1−a))\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    \n",
    "    # d = R.c\n",
    "    distance = R * c\n",
    "\n",
    "    # print('Distance between stops: ', distance)\n",
    "    return distance\n",
    "\n",
    "def cosine_similarity_distance(counts1, counts2):\n",
    "    # Calculate cosine similarity between two count vectors\n",
    "    \"\"\"\n",
    "        Calculate the cosine similarity between two count vectors.\n",
    "        The cosine similarity is a measure of similarity between two non-zero vectors of an inner product space \n",
    "        that measures the cosine of the angle between them.\n",
    "        The cosine of 0° is 1, and it is less than 1 for any other angle.\n",
    "        It is thus a judgement of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1,\n",
    "        two vectors at 90° have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude.\n",
    "        The cosine similarity is particularly used in positive space, where the outcome is neatly bounded in [0,1].\n",
    "        The cosine similarity is mathematically defined as:\n",
    "            cos(θ) = A.B / ||A||.||B||\n",
    "        where:\n",
    "            A.B = Dot product of A and B\n",
    "            ||A|| = Euclidean norm of A\n",
    "            ||B|| = Euclidean norm of B\n",
    "        :param counts1: List of counts for each ticket code for stop 1\n",
    "        :param counts2: List of counts for each ticket code for stop 2\n",
    "        :return: Cosine similarity between the two count vectors\n",
    "\n",
    "        # This function calls the cosine_similarity function from sklearn.metrics.pairwise to calculate the cosine similarity between two count vectors.\n",
    "    \"\"\"\n",
    "    similarity_matrix = cosine_similarity([counts1], [counts2])\n",
    "    similarity = 1 - similarity_matrix[0][0]\n",
    "    \n",
    "    # print('Similarity between stops: ', similarity)\n",
    "    return similarity\n",
    "\n",
    "def custom_distance(stop1, stop2, coord_weight, similarity_weight):\n",
    "    \"\"\"\n",
    "        Calculate the custom distance between two stops.\n",
    "        The custom distance is a weighted combination of the haversine distance between the two stops and the cosine similarity between the two stops.\n",
    "        The custom distance is mathematically defined as:\n",
    "            custom_distance = coord_weight * haversine_distance + similarity_weight * cosine_similarity_distance\n",
    "        where:\n",
    "            coord_weight = Weight for haversine distance\n",
    "            similarity_weight = Weight for cosine similarity distance\n",
    "        :param stop1: Tuple of (latitude, longitude, counts for each ticket code) for stop 1\n",
    "        :param stop2: Tuple of (latitude, longitude, counts for each ticket code) for stop 2\n",
    "        :param coord_weight: Weight for haversine distance\n",
    "        :param similarity_weight: Weight for cosine similarity distance\n",
    "        :return: Custom distance between the two stops\n",
    "    \"\"\"\n",
    "    # Calculate distances\n",
    "    # Calculate haversine distance between two stops\n",
    "    coord_distance = haversine_distance((stop1[0], stop1[1]), (stop2[0], stop2[1]))\n",
    "    # Calculate cosine similarity between two stops\n",
    "    count_similarity = cosine_similarity_distance(stop1[2:], stop2[2:])\n",
    "    \n",
    "    # Combine distances with appropriate weights\n",
    "    combined_distance = coord_weight * coord_distance + similarity_weight * count_similarity\n",
    "    return combined_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_count_stop is a df with columns [' LATITUDE ', ' LONGITUDE ', '1', '2', '3', '4', '5', '6', '7', 'STUD', 'RET', 'WKRS'] \n",
    "data = df_stop_count.values\n",
    "\n",
    "# Custom distance function parameters\n",
    "coord_weight = 0.3\n",
    "similarity_weight = 0.7\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "# Calculate linkage matrix using custom distance function\n",
    "# The custom distance function is a weighted average of the haversine distance between coordinates and the similarity between the stop counts\n",
    "linkage_matrix = linkage(data, method='single', metric=lambda x, y: custom_distance(x, y, coord_weight, similarity_weight))\n",
    "\n",
    "# Create a dendrogram for visualization purposes \n",
    "dendrogram(linkage_matrix, truncate_mode='lastp', p=12, leaf_rotation=90., leaf_font_size=10., show_contracted=True)\n",
    "\n",
    "# Determine clusters based on a desired threshold or number of clusters\n",
    "threshold = 0.4\n",
    "clusters = fcluster(linkage_matrix, t=threshold, criterion='distance', depth=2, R=None, monocrit=None)\n",
    "\n",
    "# print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding cluster labels to the stop count dataframe\n",
    "df_stop_count['Cluster'] = clusters\n",
    "print(df_stop_count.shape)\n",
    "df_stop_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of cluster distribution \n",
    "sns.countplot(x='Cluster', data=df_stop_count, palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folium map centered around the mean latitude and longitude\n",
    "center_lat = np.mean(df_stop_count['LATITUDE'])\n",
    "center_lon = np.mean(df_stop_count['LONGITUDE'])\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=12)\n",
    "\n",
    "cluster_colors = {\n",
    "    1: 'blue',\n",
    "    2: 'red',\n",
    "    3: 'green',\n",
    "    4: 'purple',\n",
    "    5: 'orange',\n",
    "    6: 'darkred',\n",
    "    7: 'lightred',\n",
    "    8: 'beige',\n",
    "    9: 'darkblue',\n",
    "    10: 'darkgreen',\n",
    "    11: 'cadetblue',\n",
    "    12: 'darkpurple',\n",
    "    13: 'lightblue',\n",
    "    14: 'pink',\n",
    "    15: 'lightgreen',\n",
    "    16: 'black',\n",
    "    17: 'lightgray',\n",
    "    18: 'darkgray',\n",
    "    19: 'yellow',\n",
    "    20: 'lightorange'\n",
    "}\n",
    "\n",
    "# Create markers for each stop and color them based on clusters\n",
    "for idx, row in df_stop_count.iterrows():\n",
    "    cluster_color = cluster_colors.get(row['Cluster'], 'gray')  # Default to gray if cluster color is not defined\n",
    "    folium.CircleMarker(location=[row['LATITUDE'], row['LONGITUDE']], radius=5, color=cluster_color).add_to(m)\n",
    "    # Add a label to the marker with the name of the stop obtained by geo-coding the latitude and longitude\n",
    "    # Obtain the name of the stop by geo-coding the latitude and longitude\n",
    "    from geopy.geocoders import Nominatim\n",
    "    geopy = Nominatim(user_agent=\"myapp\")\n",
    "\n",
    "    try:\n",
    "        location = geopy.reverse(f\"{row['LATITUDE']}, {row['LONGITUDE']}\").address\n",
    "    except:\n",
    "        location = \"None\"\n",
    "        \n",
    "    # Color the marker based on the cluster\n",
    "    folium.Marker(location=[row['LATITUDE'], row['LONGITUDE']], popup=location, icon=folium.Icon(color=cluster_color)).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the map to an HTML file\n",
    "# Import the necessary libraries\n",
    "from datetime import datetime\n",
    "time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "try:\n",
    "    m.save('map/' + file_name + '_clustered_' + time + '.html')\n",
    "    print('Map saved in map/' + file_name + '/' + file_name + '_clustered_' + time + '.html')\n",
    "except:\n",
    "    # Create a new folder in map folder\n",
    "    os.mkdir('map/' + file_name)\n",
    "    m.save('map/' + file_name + '/' + file_name + '_clustered_' + time + '.html')\n",
    "    print('Map saved in map/' + file_name + '/' + file_name + '_clustered_' + time + '.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply hierarchical clustering to the data of the main island of Venice (the most populated cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the data of the main island of Venice (the cluster most populated)\n",
    "cluster_main_island = df_stop_count['Cluster'].value_counts().index[0]\n",
    "\n",
    "print('The cluster with the highest number of stops is the cluster number', cluster_main_island)\n",
    "\n",
    "cluster_main_island = df_stop_count[df_stop_count['Cluster'] == cluster_main_island]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply hierarchical clustering to the data of the main island of Venice (the most populated one)\n",
    "\n",
    "data = cluster_main_island.values\n",
    "\n",
    "# Custom distance function parameters\n",
    "coord_weight = 0.3\n",
    "similarity_weight = 0.7\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "# Calculate linkage matrix using custom distance function\n",
    "# The custom distance function is a weighted average of the haversine distance between coordinates and the similarity between the stop counts\n",
    "linkage_matrix = linkage(data, method='single', metric=lambda x, y: custom_distance(x, y, coord_weight, similarity_weight))\n",
    "\n",
    "# Create a dendrogram for visualization purposes \n",
    "dendrogram(linkage_matrix, truncate_mode='lastp', p=12, leaf_rotation=90., leaf_font_size=10., show_contracted=True)\n",
    "\n",
    "# Determine clusters based on a desired threshold or number of clusters\n",
    "threshold = 0.4\n",
    "clusters = fcluster(linkage_matrix, t=threshold, criterion='distance', depth=2, R=None, monocrit=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_main_island['Cluster'] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folium map centered around the mean latitude and longitude\n",
    "center_lat = np.mean(df_stop_count['LATITUDE'])\n",
    "center_lon = np.mean(df_stop_count['LONGITUDE'])\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=12)\n",
    "\n",
    "cluster_colors = {\n",
    "    1: 'blue',\n",
    "    2: 'red',\n",
    "    3: 'green',\n",
    "    4: 'purple',\n",
    "    5: 'orange',\n",
    "    6: 'darkred',\n",
    "    7: 'lightred',\n",
    "    8: 'beige',\n",
    "    9: 'darkblue',\n",
    "    10: 'darkgreen',\n",
    "    11: 'cadetblue',\n",
    "    12: 'darkpurple',\n",
    "    13: 'lightblue',\n",
    "    14: 'pink',\n",
    "    15: 'lightgreen',\n",
    "    16: 'black',\n",
    "    17: 'lightgray',\n",
    "    18: 'darkgray',\n",
    "    19: 'yellow',\n",
    "    20: 'lightorange'\n",
    "}\n",
    "\n",
    "# Create markers for each stop and color them based on clusters\n",
    "for idx, row in cluster_main_island.iterrows():\n",
    "    cluster_color = cluster_colors.get(row['Cluster'], 'gray')  # Default to gray if cluster color is not defined\n",
    "    folium.CircleMarker(location=[row['LATITUDE'], row['LONGITUDE']], radius=5, color=cluster_color).add_to(m)\n",
    "    # Add a label to the marker with the name of the stop obtained by geo-coding the latitude and longitude\n",
    "    # Obtain the name of the stop by geo-coding the latitude and longitude\n",
    "    # from geopy.geocoders import Nominatim\n",
    "    geopy = Nominatim(user_agent=\"my-app5\")\n",
    "    try:\n",
    "        location = geopy.reverse(f\"{row['LATITUDE']}, {row['LONGITUDE']}\").address\n",
    "    except:\n",
    "        location = \"None\"\n",
    "    # Color the marker based on the cluster\n",
    "    folium.Marker(location=[row['LATITUDE'], row['LONGITUDE']], popup=location, icon=folium.Icon(color=cluster_color)).add_to(m)\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
