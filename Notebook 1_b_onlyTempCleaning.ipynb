{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASTER - Notebook 1 - Only temporal Cleaning\n",
    "### Matteo Grazioso 884055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:12.176264Z",
     "start_time": "2023-04-20T10:42:09.495939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import myfunctions as mf # Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:12.317396Z",
     "start_time": "2023-04-20T10:42:09.535034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Disply all columns and all rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all txt files in the data folder\n",
    "txt_files = mf.find_txt_files(\"data/raw\")\n",
    "\n",
    "# Choose a dataset from the list of txt files\n",
    "selected_dataset = mf.choose_dataset(txt_files)\n",
    "\n",
    "if selected_dataset:\n",
    "    print(f\"You selected the dataset {selected_dataset}\")\n",
    "else:\n",
    "    print(\"No dataset selected.\")\n",
    "\n",
    "path  = selected_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:17.073492Z",
     "start_time": "2023-04-20T10:42:09.636312Z"
    }
   },
   "outputs": [],
   "source": [
    "# The file contain the data of the validation of tickets in the city of public transport of Venice.\n",
    "\n",
    "# Import the data into a dataframe of a txt file \n",
    "# path = 'data/raw/1-validazioni.txt'                     # Period: 2022-05-13 to 2022-07-15\n",
    "# path = 'data/raw/2-esportazioneCompleta.txt'            # Period: 2023-01-23 to 2023-03-14\n",
    "# path = 'data/raw/3-esportazionePasqua23.txt'            # Period: 2023-04-04 to 2023-06-03\n",
    "\n",
    "df = pd.read_csv(path, header=0, sep='\\t')\n",
    "# Save the name of the file in a variable for future use extracting the name of the file from the path\n",
    "file_name = path.split('/')[-1].split('.')[0]\n",
    "# Remove the number and the - character from the head of the file name\n",
    "file_name = file_name [file_name.find('-')+1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:17.077302Z",
     "start_time": "2023-04-20T10:42:17.072317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:17.185411Z",
     "start_time": "2023-04-20T10:42:17.073448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the last 5 rows of the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:17.266216Z",
     "start_time": "2023-04-20T10:42:17.116116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a subset of the data with the first 10% of the rows and the last 10% of the rows\n",
    "# df = df.iloc[:int(len(df)*0.1),:]\n",
    "# df = df.append(df.iloc[-int(len(df)*0.1):,:])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:40.498916Z",
     "start_time": "2023-04-20T10:42:17.166251Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dates and hour of the validation of the ticket are in the same column 'DATA_VALIDAZIONE'\n",
    "# Split the column 'DATA_VALIDAZIONE' into two columns 'DATA' and 'ORA' and convert them to datetime format\n",
    "df.insert(0, 'DATA', pd.to_datetime(df['DATA_VALIDAZIONE'].str.split(' ').str[0], format='%d/%m/%Y'))\n",
    "df.insert(1, 'ORA', pd.to_datetime(df['DATA_VALIDAZIONE'].str.split(' ').str[1], format='%H:%M').dt.time)\n",
    "\n",
    "# Drop the column 'DATA_VALIDAZIONE'\n",
    "# df.drop('DATA_VALIDAZIONE', axis=1, inplace=True)\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:41.904782Z",
     "start_time": "2023-04-20T10:42:40.646208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the format of the timestamp\n",
    "df['DATA_VALIDAZIONE'] = pd.to_datetime(df['DATA_VALIDAZIONE'], format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:44.579560Z",
     "start_time": "2023-04-20T10:42:42.039506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the date of the first and last validation using both data and hour\n",
    "print('First validation: ', df['DATA'].min(), df['ORA'].min())\n",
    "print('Last validation: ', df['DATA'].max(), df['ORA'].max())\n",
    "\n",
    "# Print the number of Serial numbers\n",
    "print('Number of Serial numbers: ', df['SERIALE'].nunique())\n",
    "\n",
    "# Print the number of validation (rows)\n",
    "print('Number of validation: ', df.shape[0])\n",
    "\n",
    "# Print the number of tickets\n",
    "print('Number of tickets: ', df['DESCRIZIONE_TITOLO'].nunique())\n",
    "# Print the number of titolo\n",
    "print('Number of titolo: ', df['TITOLO'].nunique())\n",
    "# TODO: why the number of unique TITOLO is different from the number of DESCRIZIONE_TITOLO?\n",
    "\n",
    "# Print the number of FERMATA\n",
    "print('Number of FERMATA: ', df['FERMATA'].nunique())\n",
    "# Print the number of DESCRIZIONE\n",
    "print('Number of DESCRIZIONE: ', df['DESCRIZIONE'].nunique())\n",
    "# TODO: why the number of unique DESCRIZIONE is different from the number of FERMATA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:45.125089Z",
     "start_time": "2023-04-20T10:42:45.050181Z"
    }
   },
   "outputs": [],
   "source": [
    "# Which is the most used ticket?\n",
    "df['DESCRIZIONE_TITOLO'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:46.851812Z",
     "start_time": "2023-04-20T10:42:45.060054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Which is the most frequent validation in date and hour?\n",
    "# Date and hour are in two different columns; DATA_VALIDAZIONE does not exist anymore\n",
    "df.groupby(['DATA', 'ORA'])['SERIALE'].count().sort_values(ascending=False).head(10)\n",
    "# TODO: #4 Re-aswer the question of the most frequent validation after cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:47.431904Z",
     "start_time": "2023-04-20T10:42:47.370409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Which is the most frequent FERMATA?\n",
    "df['DESCRIZIONE'].value_counts().head(10)\n",
    "# TODO: #4 Re-aswer the question of the most frequent FERMATA after cleaning operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useless stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:45:12.824342Z",
     "start_time": "2023-04-20T10:45:04.756819Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the serial with the hightest number of validations, and the same for each ticket profile, save the results in a dictionary\n",
    "dict_serial = {}\n",
    "for ticket in df['TICKET_CODE'].unique():\n",
    "    dict_serial[ticket] = df[df['TICKET_CODE'] == ticket]['SERIALE'].value_counts().index[0]\n",
    "\n",
    "# Print the serial with the hightest number of validations, and the same for each ticket profile\n",
    "for ticket in df['TICKET_CODE'].unique():\n",
    "  print('The serial with the hightest number of validations for the ticket profile {} is: {}'.format(ticket, dict_serial[ticket]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:45:12.933493Z",
     "start_time": "2023-04-20T10:45:12.816410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reset the index of the df and drop the old index in order to have a new index starting from 0 to the number of rows\n",
    "# It is necessary to have a new index because the groupby function has created a multi-index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'MIN_TEMPORAL_GAP' that contains the minimum temporal gap between two validations for the same serial and fermata in minutes\n",
    "df = df.groupby(['SERIALE','DATA', 'DESCRIZIONE']).apply(lambda x: x.assign(MIN_TEMPORAL_GAP = x['DATA_VALIDAZIONE'].diff().dt.total_seconds()/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MIN_TEMPORAL_GAP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows have a minimum temporal gap equal to NaN?\n",
    "df[df['MIN_TEMPORAL_GAP'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning operation: remove the rows using the minimum temporal gap\n",
    "\n",
    "# Find a reasonable delta of MIN_TEMPORAL_GAP to remove the rows that have a minimum temporal gap for the same serial and fermata less than this delta\n",
    "# Print the minimum value of the column MIN_TEMPORAL_GAP\n",
    "print('The minimum value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].min()))\n",
    "\n",
    "# Print the maximum value of the column MIN_TEMPORAL_GAP\n",
    "print('The maximum value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].max()))\n",
    "\n",
    "# Print the mean value of the column MIN_TEMPORAL_GAP\n",
    "print('The mean value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].mean()))\n",
    "\n",
    "# Print the median value of the column MIN_TEMPORAL_GAP\n",
    "print('The median value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].median()))\n",
    "\n",
    "# Print the standard deviation of the column MIN_TEMPORAL_GAP\n",
    "print('The standard deviation of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].std()))\n",
    "\n",
    "# Print the 0.05th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 0.05th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.05)))\n",
    "\n",
    "# Print the 0.10th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 0.10th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.10)))\n",
    "\n",
    "# Print the 25th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 25th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.25)))\n",
    "\n",
    "# Print the 75th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 75th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.75)))\n",
    "\n",
    "# Print the 90th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 90th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.90)))\n",
    "\n",
    "# Print the 95th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 95th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.95)))\n",
    "\n",
    "# Print the 99th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 99th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.99)))\n",
    "\n",
    "# Print the 99.9th percentile of the column MIN_TEMPORAL_GAP\n",
    "print('The 99.9th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.999)))\n",
    "\n",
    "# Decide the delta of MIN_TEMPORAL_GAP to remove the rows that have a minimum temporal gap for the same serial and fermata less than this delta\n",
    "delta = df['MIN_TEMPORAL_GAP'].quantile(0.1)\n",
    "if delta == 0:\n",
    "    delta = df['MIN_TEMPORAL_GAP'].quantile(0.25)\n",
    "if delta == 0:\n",
    "    delta = df['MIN_TEMPORAL_GAP'].median()\n",
    "print('The delta of MIN_TEMPORAL_GAP is: {}'.format(delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning operation: remove the rows using the minimum temporal gap\n",
    "\n",
    "# Save the number of rows before the cleaning operation\n",
    "shape_before = df.shape[0]\n",
    "\n",
    "# Delete the rows that have a minimum temporal gap for the same serial and fermata more than the delta calculated before.\n",
    "# Do not remove the rows with NaN values because they are the first validations of the day of a specific serial and fermata usefull for the analysis\n",
    "df = df[(df['MIN_TEMPORAL_GAP'] > delta) | (df['MIN_TEMPORAL_GAP'].isna())]\n",
    "\n",
    "# Print the number of rows before and after the cleaning operation and the difference\n",
    "print('The number of rows before the cleaning operation is: {}'.format(shape_before))\n",
    "print('The number of rows after the cleaning operation is: {}'.format(df.shape[0]))\n",
    "print('The difference is: {}'.format(shape_before - df.shape[0]))\n",
    "# Calculate the percentage of rows that has just been deleted\n",
    "print('The percentage of rows that has just been deleted is: {}%'.format(round((shape_before - df.shape[0])/shape_before*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the column MIN_TEMPORAL_GAP because it is not useful anymore\n",
    "df.drop('MIN_TEMPORAL_GAP', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:02:21.784304Z",
     "start_time": "2023-04-20T13:53:45.129009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe, copied from the original one\n",
    "df_new = df.copy() \n",
    "\n",
    "# Print the head of the new dataframe\n",
    "print(df_new.head())\n",
    "\n",
    "# Export the new dataframe in a txt file\n",
    "# The name of the file is dataset_cleaned followed by the name (file_name variable) of the file that has been cleaned with txt extension\n",
    "name_file = 'dataset_cleaned_temp' + file_name.split('.')[0] + '.txt'\n",
    "df_new.to_csv('data/processed/' + name_file, sep='\\t', index=False)\n",
    "\n",
    "print('The script has finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
