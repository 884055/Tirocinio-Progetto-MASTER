{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASTER - Notebook 1 - Only temporal Cleaning\n",
    "### Matteo Grazioso 884055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:12.176264Z",
     "start_time": "2023-04-20T10:42:09.495939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import myfunctions as mf # Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:12.317396Z",
     "start_time": "2023-04-20T10:42:09.535034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Disply all columns and all rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all txt files in the data folder\n",
    "txt_files = mf.find_txt_files(\"data/raw\")\n",
    "\n",
    "# Choose a dataset from the list of txt files\n",
    "selected_dataset = mf.choose_dataset(txt_files)\n",
    "\n",
    "if selected_dataset:\n",
    "    print(f\"You selected the dataset {selected_dataset}\")\n",
    "else:\n",
    "    print(\"No dataset selected.\")\n",
    "\n",
    "path  = selected_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:17.073492Z",
     "start_time": "2023-04-20T10:42:09.636312Z"
    }
   },
   "outputs": [],
   "source": [
    "# The file contain the data of the validation of tickets in the city of public transport of Venice.\n",
    "\n",
    "# Import the data into a dataframe of a txt file \n",
    "# path = 'data/raw/1-validazioni.txt'                     # Period: 2022-05-13 to 2022-07-15\n",
    "# path = 'data/raw/2-esportazioneCompleta.txt'            # Period: 2023-01-23 to 2023-03-14\n",
    "# path = 'data/raw/3-esportazionePasqua23.txt'            # Period: 2023-04-04 to 2023-06-03\n",
    "\n",
    "df = pd.read_csv(path, header=0, sep='\\t')\n",
    "# Save the name of the file in a variable for future use extracting the name of the file from the path\n",
    "file_name = path.split('/')[-1].split('.')[0]\n",
    "# Remove the number and the - character from the head of the file name\n",
    "file_name = file_name [file_name.find('-')+1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:17.077302Z",
     "start_time": "2023-04-20T10:42:17.072317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:17.185411Z",
     "start_time": "2023-04-20T10:42:17.073448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the last 5 rows of the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:17.266216Z",
     "start_time": "2023-04-20T10:42:17.116116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a subset of the data with the first 10% of the rows and the last 10% of the rows\n",
    "# df = df.iloc[:int(len(df)*0.01),:]\n",
    "# df = df.append(df.iloc[-int(len(df)*0.1):,:])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:40.498916Z",
     "start_time": "2023-04-20T10:42:17.166251Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dates and hour of the validation of the ticket are in the same column 'DATA_VALIDAZIONE'\n",
    "# Split the column 'DATA_VALIDAZIONE' into two columns 'DATA' and 'ORA' and convert them to datetime format\n",
    "df.insert(0, 'DATA', pd.to_datetime(df['DATA_VALIDAZIONE'].str.split(' ').str[0], format='%d/%m/%Y'))\n",
    "df.insert(1, 'ORA', pd.to_datetime(df['DATA_VALIDAZIONE'].str.split(' ').str[1], format='%H:%M').dt.time)\n",
    "\n",
    "# Drop the column 'DATA_VALIDAZIONE'\n",
    "# df.drop('DATA_VALIDAZIONE', axis=1, inplace=True)\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:41.904782Z",
     "start_time": "2023-04-20T10:42:40.646208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the format of the timestamp\n",
    "df['DATA_VALIDAZIONE'] = pd.to_datetime(df['DATA_VALIDAZIONE'], format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:44.579560Z",
     "start_time": "2023-04-20T10:42:42.039506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the date of the first and last validation using both data and hour\n",
    "print('First validation: ', df['DATA'].min(), df['ORA'].min())\n",
    "print('Last validation: ', df['DATA'].max(), df['ORA'].max())\n",
    "\n",
    "# Print the number of Serial numbers\n",
    "print('Number of Serial numbers: ', df['SERIALE'].nunique())\n",
    "\n",
    "# Print the number of validation (rows)\n",
    "print('Number of validation: ', df.shape[0])\n",
    "\n",
    "# Print the number of tickets\n",
    "print('Number of tickets: ', df['DESCRIZIONE_TITOLO'].nunique())\n",
    "# Print the number of titolo\n",
    "print('Number of titolo: ', df['TITOLO'].nunique())\n",
    "# TODO: why the number of unique TITOLO is different from the number of DESCRIZIONE_TITOLO?\n",
    "\n",
    "# Print the number of FERMATA\n",
    "print('Number of FERMATA: ', df['FERMATA'].nunique())\n",
    "# Print the number of DESCRIZIONE\n",
    "print('Number of DESCRIZIONE: ', df['DESCRIZIONE'].nunique())\n",
    "# TODO: why the number of unique DESCRIZIONE is different from the number of FERMATA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:45.125089Z",
     "start_time": "2023-04-20T10:42:45.050181Z"
    }
   },
   "outputs": [],
   "source": [
    "# Which is the most used ticket?\n",
    "df['DESCRIZIONE_TITOLO'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:46.851812Z",
     "start_time": "2023-04-20T10:42:45.060054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Which is the most frequent validation in date and hour?\n",
    "# Date and hour are in two different columns; DATA_VALIDAZIONE does not exist anymore\n",
    "df.groupby(['DATA', 'ORA'])['SERIALE'].count().sort_values(ascending=False).head(10)\n",
    "# TODO: #4 Re-aswer the question of the most frequent validation after cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:42:47.431904Z",
     "start_time": "2023-04-20T10:42:47.370409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Which is the most frequent FERMATA?\n",
    "df['DESCRIZIONE'].value_counts().head(10)\n",
    "# TODO: #4 Re-aswer the question of the most frequent FERMATA after cleaning operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column TICKET_CODE will be filled with the code of the ticket profile according to the ticket type and the ticket validity as follows:\n",
    "\n",
    "**1.** One-day ticket\n",
    "\n",
    "**2.** Two-day ticket\n",
    "\n",
    "**3.** Three-day ticket\n",
    "\n",
    "**4.** Weekly ticket (Seven-day ticket)\n",
    "\n",
    "**5.** Monthly ticket\n",
    "\n",
    "**5-STUD.** Monthly ticket for students\n",
    "\n",
    "**5-RET.** Monthly ticket for retirees\n",
    "\n",
    "**5-WKRS.** Monthly ticket for workers\n",
    "\n",
    "**6.** Annual ticket\n",
    "\n",
    "**6-STUD.** Annual ticket for students\n",
    "\n",
    "**6-RET.** Annual ticket for retirees\n",
    "\n",
    "**6-WKRS.** Annual ticket for workers\n",
    "\n",
    "**7.** 75 minutes ticket\n",
    "\n",
    "**8.** Other ticket (if it is necessary to add other types of tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignTicketCode(df_a: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        This function assigns a ticket code to each row of the dataframe.\n",
    "        :param df: the dataframe\n",
    "        :return: the dataframe with the new column TICKET_CODE\n",
    "    \"\"\"\n",
    "    # Add a new column with the code profile of the ticket\n",
    "    df_a.insert(7, \"TICKET_CODE\", 'TBD')\n",
    "\n",
    "    # Define the dictionary of ticket codes\n",
    "    dict_tickets = {'1': 'One-day ticket', '2': 'Two-day ticket', '3': 'Three-day ticket', \n",
    "                '4': 'Seven-day ticket', \n",
    "                '5': 'Monthly ticket', '5-STUD': 'Monthly ticket for students',\n",
    "                '5-RET': 'Monthly ticket for retired', '5-WKRS': 'Monthly ticket for workers',\n",
    "                '6': 'Annual ticket', '6-STUD': 'Annual ticket for students', '6-RET': 'Annual ticket for retired',\n",
    "                '6-WKRS': 'Annual ticket for workers',\n",
    "                '7': '75 minutes ticket', '8': 'Other ticket'}\n",
    "    \n",
    "    # Convert the column 'DESCRIZIONE_TITOLO' into upper case \n",
    "    df_a['DESCRIZIONE_TITOLO'] = df_a['DESCRIZIONE_TITOLO'].str.upper()\n",
    "\n",
    "    # One-day ticket\n",
    "    df_a.loc[df_a['DESCRIZIONE_TITOLO'].str.contains('GIORNALIERO|24H|24ORE|24 ORE|DAILY'), 'TICKET_CODE'] = '1'\n",
    "    # Two-day ticket\n",
    "    df_a.loc[df_a['DESCRIZIONE_TITOLO'].str.contains('48H|48ORE|48 ORE'), 'TICKET_CODE'] = '2'\n",
    "    # Three-day ticket\n",
    "    df_a.loc[df_a['DESCRIZIONE_TITOLO'].str.contains('72H|72ORE|72 ORE'), 'TICKET_CODE'] = '3'\n",
    "    # Seven-day ticket\n",
    "    df_a[df_a['DESCRIZIONE_TITOLO'].str.contains('7GG|7DAYS|7 DAYS')]['DESCRIZIONE_TITOLO'].value_counts()\n",
    "    # Monthly ticket\n",
    "    df_a.loc[df_a['DESCRIZIONE_TITOLO'].str.contains('MENSILE|30GG|30 GG|MENS'), 'TICKET_CODE'] = '5'\n",
    "    ## Monthly ticket for students\n",
    "    df_a.loc[(df_a['TICKET_CODE'] == '5') & (df_a['DESCRIZIONE_TITOLO'].str.contains('STUDENTE|STUD')), 'TICKET_CODE'] = '5-STUD'\n",
    "    ## Monthly ticket for retired\n",
    "    df_a.loc[(df_a['TICKET_CODE'] == '5') & (df_a['DESCRIZIONE_TITOLO'].str.contains('OVER 65|65+|PENSIONATI')), 'TICKET_CODE'] = '5-RET'\n",
    "    ## Monthly ticket for workers\n",
    "    df_a.loc[(df_a['TICKET_CODE'] == '5') & (df_a['DESCRIZIONE_TITOLO'].str.contains('LAVORATORE|LAV')), 'TICKET_CODE'] = '5-WKRS'\n",
    "    ## DDRG 1201-1297/2022\n",
    "    df_a.loc[df_a['DESCRIZIONE_TITOLO'].str.contains('DDGR1201-1297/2022'), 'TICKET_CODE'] = '5'\n",
    "    # Yearly ticket\n",
    "    df_a.loc[df_a['DESCRIZIONE_TITOLO'].str.contains('ANNUALE|ANN|12MESI|12 MESI'), 'TICKET_CODE'] = '6'\n",
    "    ## Yearly ticket for students\n",
    "    df_a.loc[(df_a['TICKET_CODE'] == '6') & (df_a['DESCRIZIONE_TITOLO'].str.contains('STUDENTE|STUD|STUD')), 'TICKET_CODE'] = '6-STUD'\n",
    "    ## Yearly ticket for retired\n",
    "    df_a.loc[(df_a['TICKET_CODE'] == '6') & (df_a['DESCRIZIONE_TITOLO'].str.contains('OVER 65|65+|PENSIONATI')), 'TICKET_CODE'] = '6-RET'\n",
    "    ## Yearly ticket for workers\n",
    "    df_a.loc[(df_a['TICKET_CODE'] == '6') & (df_a['DESCRIZIONE_TITOLO'].str.contains('LAVORATORE|LAV|LAV')), 'TICKET_CODE'] = '6-WKRS'\n",
    "    ## Student yearly ticket\n",
    "    df_a.loc[(df_a['DESCRIZIONE_TITOLO'].str.contains('STUDENTE|STUD|STUD')) & ~ (df_a['TICKET_CODE'].isin(['5-STUD', '6-STUD'])), 'TICKET_CODE'] = '6-STUD'\n",
    "    # 75 minutes ticket\n",
    "    df_a.loc[df_a['DESCRIZIONE_TITOLO'].str.contains('75\\'|75MIN|75 MIN'), 'TICKET_CODE'] = '7'\n",
    "    # Other ticket\n",
    "    df_a.loc[~df_a['TICKET_CODE'].isin(['1','2','3','4','5','5-STUD','5-WKRS','5-RET','6','6-STUD','6-WKRS','6-RET','7']), 'TICKET_CODE'] = '8'\n",
    "\n",
    "    # Plot a pie chart of the column 'TICKET_CODE'\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    df_a['TICKET_CODE'].value_counts().sort_index().plot.pie(startangle=90)\n",
    "\n",
    "    # Add the name of the ticket profile on the pie chart\n",
    "    plt.legend(labels=df_a['TICKET_CODE'].value_counts().sort_index().rename(dict_tickets).index, loc='center left', bbox_to_anchor=(1, 0, 0.5, 1), fontsize=15)\n",
    "\n",
    "    plt.title('Pie chart of the column TICKET_CODE', fontsize=20)\n",
    "    plt.ylabel('')\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.show()\n",
    "\n",
    "    # Delete stamps with ticket code 8\n",
    "    df_a = df_a[df_a['TICKET_CODE'] != '8']\n",
    "\n",
    "    return df_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = assignTicketCode(df)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useless stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T10:45:12.933493Z",
     "start_time": "2023-04-20T10:45:12.816410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reset the index of the df and drop the old index in order to have a new index starting from 0 to the number of rows\n",
    "# It is necessary to have a new index because the groupby function has created a multi-index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'MIN_TEMPORAL_GAP' that contains the minimum temporal gap between two validations for the same serial and fermata in minutes\n",
    "df = df.groupby(['SERIALE','DATA', 'DESCRIZIONE']).apply(lambda x: x.assign(MIN_TEMPORAL_GAP = x['DATA_VALIDAZIONE'].diff().dt.total_seconds()/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MIN_TEMPORAL_GAP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows have a minimum temporal gap equal to NaN?\n",
    "df[df['MIN_TEMPORAL_GAP'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a file to save the information about the results of the cleaning process\n",
    "# File txt with name: \"cleaningResults + filename + date.txt\"\n",
    "import datetime\n",
    "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "with open('data/processed/cleaningResults_' + file_name + '_' + date + '.txt', 'w') as f:\n",
    "    f.write('File name: ' + file_name + '\\n')\n",
    "    f.write('Operation starts at: ' + date + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning operation: remove the rows using the minimum temporal gap\n",
    "\n",
    "# Find a reasonable delta of MIN_TEMPORAL_GAP to remove the rows that have a minimum temporal gap for the same serial and fermata less than this delta\n",
    "with open('data/processed/cleaningResults_' + file_name + '_' + date + '.txt', 'a') as f:\n",
    "    # Print the minimum value of the column MIN_TEMPORAL_GAP\n",
    "    print('The minimum value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].min()))\n",
    "    f.write('The minimum value of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].min()))\n",
    "\n",
    "    # Print the maximum value of the column MIN_TEMPORAL_GAP\n",
    "    print('The maximum value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].max()))\n",
    "    f.write('The maximum value of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].max()))\n",
    "\n",
    "    # Print the mean value of the column MIN_TEMPORAL_GAP\n",
    "    print('The mean value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].mean()))\n",
    "    f.write('The mean value of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].mean()))\n",
    "\n",
    "    # Print the median value of the column MIN_TEMPORAL_GAP\n",
    "    print('The median value of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].median()))\n",
    "    f.write('The median value of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].median()))\n",
    "\n",
    "    # Print the standard deviation of the column MIN_TEMPORAL_GAP\n",
    "    print('The standard deviation of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].std()))\n",
    "    f.write('The standard deviation of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].std()))\n",
    "\n",
    "    # Print the 0.05th percentile of the column MIN_TEMPORAL_GAP\n",
    "    print('The 0.05th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.05)))\n",
    "    f.write('The 0.05th percentile of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].quantile(0.05)))\n",
    "\n",
    "    # Print the 0.10th percentile of the column MIN_TEMPORAL_GAP\n",
    "    print('The 0.10th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.10)))\n",
    "    f.write('The 0.10th percentile of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].quantile(0.10)))\n",
    "\n",
    "    # Print the 25th percentile of the column MIN_TEMPORAL_GAP\n",
    "    print('The 25th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.25)))\n",
    "    f.write('The 25th percentile of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].quantile(0.25)))\n",
    "\n",
    "    # Print the 75th percentile of the column MIN_TEMPORAL_GAP\n",
    "    print('The 75th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.75)))\n",
    "    f.write('The 75th percentile of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].quantile(0.75)))\n",
    "\n",
    "    # Print the 90th percentile of the column MIN_TEMPORAL_GAP\n",
    "    print('The 90th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.90)))\n",
    "    f.write('The 90th percentile of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].quantile(0.90)))\n",
    "\n",
    "    # Print the 95th percentile of the column MIN_TEMPORAL_GAP\n",
    "    print('The 95th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.95)))\n",
    "    f.write('The 95th percentile of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].quantile(0.95)))\n",
    "\n",
    "    # Print the 99th percentile of the column MIN_TEMPORAL_GAP\n",
    "    print('The 99th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.99)))\n",
    "    f.write('The 99th percentile of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].quantile(0.99)))\n",
    "\n",
    "    # Print the 99.9th percentile of the column MIN_TEMPORAL_GAP\n",
    "    print('The 99.9th percentile of the column MIN_TEMPORAL_GAP is: {}'.format(df['MIN_TEMPORAL_GAP'].quantile(0.999)))\n",
    "    f.write('The 99.9th percentile of the column MIN_TEMPORAL_GAP is: {}\\n'.format(df['MIN_TEMPORAL_GAP'].quantile(0.999)))\n",
    "\n",
    "    # Decide the delta of MIN_TEMPORAL_GAP to remove the rows that have a minimum temporal gap for the same serial and fermata less than this delta\n",
    "    delta = df['MIN_TEMPORAL_GAP'].quantile(0.1)\n",
    "    if delta == 0:\n",
    "        delta = df['MIN_TEMPORAL_GAP'].quantile(0.25)\n",
    "    if delta == 0:\n",
    "        delta = df['MIN_TEMPORAL_GAP'].median()\n",
    "    print('The delta of MIN_TEMPORAL_GAP is: {}'.format(delta))\n",
    "    f.write('The delta of MIN_TEMPORAL_GAP is: {}\\n'.format(delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning operation: remove the rows using the minimum temporal gap\n",
    "\n",
    "# Save the number of rows before the cleaning operation\n",
    "shape_before = df.shape[0]\n",
    "\n",
    "# Delete the rows that have a minimum temporal gap for the same serial and fermata more than the delta calculated before.\n",
    "# Do not remove the rows with NaN values because they are the first validations of the day of a specific serial and fermata usefull for the analysis\n",
    "df = df[(df['MIN_TEMPORAL_GAP'] > delta) | (df['MIN_TEMPORAL_GAP'].isna())]\n",
    "\n",
    "with open('data/processed/cleaningResults_' + file_name + '_' + date + '.txt', 'a') as f:\n",
    "    # Print the number of rows before and after the cleaning operation and the difference\n",
    "    print('The number of rows before the cleaning operation is: {}'.format(shape_before))\n",
    "    f.write('The number of rows before the cleaning operation is: {}\\n'.format(shape_before))\n",
    "    print('The number of rows after the cleaning operation is: {}'.format(df.shape[0]))\n",
    "    f.write('The number of rows after the cleaning operation is: {}\\n'.format(df.shape[0]))\n",
    "    print('The difference is: {}'.format(shape_before - df.shape[0]))\n",
    "    f.write('The difference is: {}\\n'.format(shape_before - df.shape[0]))\n",
    "\n",
    "    # Calculate the percentage of rows that has just been deleted\n",
    "    print('The percentage of rows that has just been deleted is: {}%'.format(round((shape_before - df.shape[0])/shape_before*100, 2)))\n",
    "    f.write('The percentage of rows that has just been deleted is: {}%\\n'.format(round((shape_before - df.shape[0])/shape_before*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the column MIN_TEMPORAL_GAP because it is not useful anymore\n",
    "df.drop('MIN_TEMPORAL_GAP', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T14:02:21.784304Z",
     "start_time": "2023-04-20T13:53:45.129009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe, copied from the original one\n",
    "df_new = df.copy() \n",
    "\n",
    "# Print the head of the new dataframe\n",
    "print(df_new.head())\n",
    "\n",
    "# Export the new dataframe in a txt file\n",
    "# The name of the file is dataset_cleaned followed by the name (file_name variable) of the file that has been cleaned with txt extension\n",
    "name_file = 'dataset_cleaned_temp' + file_name.split('.')[0] + '.txt'\n",
    "df_new.to_csv('data/processed/' + name_file, sep='\\t', index=False)\n",
    "\n",
    "print('The script has finished')\n",
    "with open('data/processed/cleaningResults_' + file_name + '_' + date + '.txt', 'a') as f:\n",
    "    f.write('The script has finished\\n')\n",
    "    f.write('The name of the file is: ' + name_file + '\\n')\n",
    "    date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    f.write('Operation completed at: ' + date + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
